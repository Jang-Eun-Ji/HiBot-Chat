# chatbot_hwp.py
# Updated chatbot to work with HWP document database

import os
import duckdb
import json
import numpy as np
from haystack import Pipeline
from haystack.components.embedders import SentenceTransformersTextEmbedder
from haystack.components.builders import PromptBuilder
from haystack.dataclasses import Document
import google.generativeai as genai
from dotenv import load_dotenv

# --- 0. API í‚¤ ì„¤ì • ---
load_dotenv()
google_api_key = os.getenv("GOOGLE_API_KEY")
if google_api_key:
    os.environ["GOOGLE_API_KEY"] = google_api_key
    genai.configure(api_key=google_api_key)
    print("âœ… Google API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    print("âš ï¸ ê²½ê³ : GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# --- 1. ê·œì¹™ ê¸°ë°˜ FAQ ë°ì´í„°ë² ì´ìŠ¤ ---
FIXED_FAQ_DATABASE = {
    "ì—°ì°¨ ì–´ë–»ê²Œ ì‚¬ìš©": "ì—°ì°¨ ì‚¬ìš©ì€ ê·¸ë£¹ì›¨ì–´ ê·¼íƒœê´€ë¦¬ ì‹œìŠ¤í…œì—ì„œ ì‹ ì²­í•˜ì‹¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì—°ì°¨ëŠ” ìž…ì‚¬ì¼ ê¸°ì¤€ìœ¼ë¡œ ë§¤ë…„ 15ì¼ì´ ë¶€ì—¬ë˜ë©°, ë¯¸ì‚¬ìš© ì—°ì°¨ëŠ” ë‹¤ìŒ í•´ë¡œ ì´ì›”ë©ë‹ˆë‹¤.",
    "ì¶œìž¥ ì‹ ì²­": "ì¶œìž¥ì€ ê·¸ë£¹ì›¨ì–´ì˜ 'ê²°ìž¬' â†’ 'ì¶œìž¥ì‹ ì²­' ë©”ë‰´ì—ì„œ ì‹ ì²­í•˜ì„¸ìš”. ì¶œìž¥ ì™„ë£Œ í›„ 7ì¼ ì´ë‚´ì— ì¶œìž¥ë³´ê³ ì„œë¥¼ ì œì¶œí•´ì•¼ í•©ë‹ˆë‹¤.",
    "ë²•ì¸ì¹´ë“œ ì‚¬ìš©": "ë²•ì¸ì¹´ë“œëŠ” ì—…ë¬´ ê´€ë ¨ ê²½ë¹„ë§Œ ì‚¬ìš© ê°€ëŠ¥í•˜ë©°, ì‚¬ìš© í›„ ì˜ìˆ˜ì¦ê³¼ í•¨ê»˜ ì •ì‚° ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.",
    "ë³µë¬´ ê·œì •": "ì¶œê·¼ì‹œê°„ì€ ì˜¤ì „ 9ì‹œ, í‡´ê·¼ì‹œê°„ì€ ì˜¤í›„ 6ì‹œì´ë©°, ì ì‹¬ì‹œê°„ì€ 12ì‹œ~1ì‹œìž…ë‹ˆë‹¤. ì§€ê° ì‹œ ê·¸ë£¹ì›¨ì–´ì—ì„œ ì§€ê°ì‚¬ìœ ë¥¼ ìž…ë ¥í•´ì£¼ì„¸ìš”.",
    "íœ´ê°€ ì‹ ì²­": "íœ´ê°€ëŠ” ê·¸ë£¹ì›¨ì–´ ê·¼íƒœê´€ë¦¬ì—ì„œ ì‚¬ì „ ì‹ ì²­í•˜ì‹œê¸° ë°”ëžë‹ˆë‹¤. ê²½ì¡°ì‚¬ íœ´ê°€ì˜ ê²½ìš° ê´€ë ¨ ì¦ë¹™ì„œë¥˜ê°€ í•„ìš”í•©ë‹ˆë‹¤."
}

# --- 2. ê²½ë¡œ ë° ëª¨ë¸ ì„¤ì • ---
EMBEDDING_MODEL = "jhgan/ko-sbert-nli"
DB_PATH_SIMPLE = "hibot_store_simple.db"  # ê°„ë‹¨ ë²„ì „ (í…ìŠ¤íŠ¸ ê²€ìƒ‰)
DB_PATH_EMBEDDING = "hibot_store.db"      # ìž„ë² ë”© ë²„ì „

# --- 3. HWP ë¬¸ì„œ ê²€ìƒ‰ê¸° ---
class HWPDocumentSearcher:
    """HWP ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ìƒ‰ì„ ìˆ˜í–‰"""
    
    def __init__(self, db_path):
        self.db_path = db_path
        self.conn = None
        self._connect()
    
    def _connect(self):
        try:
            self.conn = duckdb.connect(self.db_path)
            print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ: {self.db_path}")
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
    
    def search_documents(self, query, limit=5):
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰"""
        if not self.conn:
            return []
        
        try:
            # ê°„ë‹¨í•œ ë‹¨ì¼ í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ ë³€ê²½
            sql = """
                SELECT id, content, meta,
                       length(content) - length(replace(lower(content), lower(?), '')) as relevance_score
                FROM documents 
                WHERE lower(content) LIKE lower(?)
                ORDER BY relevance_score DESC
                LIMIT ?
            """
            
            pattern = f"%{query}%"
            result = self.conn.execute(sql, (query, pattern, limit)).fetchall()
            
            documents = []
            for row in result:
                doc_id, content, meta_str, score = row
                meta = json.loads(meta_str) if meta_str else {}
                meta['search_score'] = score
                
                documents.append(Document(
                    id=doc_id,
                    content=content,
                    meta=meta
                ))
            
            return documents
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def get_statistics(self):
        """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì •ë³´"""
        if not self.conn:
            return {}
        
        try:
            total_docs = self.conn.execute("SELECT COUNT(*) FROM documents").fetchone()[0]
            
            file_stats = self.conn.execute("""
                SELECT JSON_EXTRACT_STRING(meta, '$.file_name') as filename, 
                       COUNT(*) as chunk_count
                FROM documents 
                GROUP BY filename 
                ORDER BY chunk_count DESC
                LIMIT 5
            """).fetchall()
            
            return {
                "total_documents": total_docs,
                "top_files": file_stats
            }
        except Exception as e:
            print(f"âŒ í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return {}

# --- 4. Gemini API ì‘ë‹µ ìƒì„±ê¸° ---
class GeminiResponseGenerator:
    """Google Gemini APIë¥¼ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„±"""
    
    def __init__(self):
        self.model_name = "gemini-1.5-flash"
        self.available = google_api_key is not None
    
    def generate_response(self, query, documents):
        """ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µ ìƒì„±"""
        if not self.available:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. AI ì‘ë‹µ ìƒì„± ì„œë¹„ìŠ¤ê°€ í˜„ìž¬ ì´ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ê´€ë¦¬ìžì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
        
        try:
            # ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
            context_parts = []
            for i, doc in enumerate(documents[:3], 1):  # ìƒìœ„ 3ê°œ ë¬¸ì„œë§Œ ì‚¬ìš©
                filename = doc.meta.get('file_name', 'ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼')
                content_preview = doc.content[:500]  # ì²˜ìŒ 500ìžë§Œ
                context_parts.append(f"[ë¬¸ì„œ {i}: {filename}]\n{content_preview}")
            
            context = "\n\n".join(context_parts)
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = f"""
ë‹¤ìŒì€ ì¡°ì§ ë‚´ë¶€ ê·œì • ë° ì—…ë¬´ ê´€ë ¨ ë¬¸ì„œë“¤ìž…ë‹ˆë‹¤. ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì´ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ìž‘ì„±í•´ì£¼ì„¸ìš”.

=== ê´€ë ¨ ë¬¸ì„œ ë‚´ìš© ===
{context}

=== ì‚¬ìš©ìž ì§ˆë¬¸ ===
{query}

=== ë‹µë³€ ê°€ì´ë“œë¼ì¸ ===
1. ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”
2. ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ëŠ” ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”
3. í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
4. í•„ìš”ì‹œ í•´ë‹¹ ê·œì •ì´ë‚˜ ì§€ì¹¨ì˜ ì œëª©ì„ ì–¸ê¸‰í•˜ì„¸ìš”
5. ì¶”ê°€ ë¬¸ì˜ê°€ í•„ìš”í•œ ê²½ìš° ë‹´ë‹¹ ë¶€ì„œ í™•ì¸ì„ ì•ˆë‚´í•˜ì„¸ìš”

ë‹µë³€:
"""

            # Gemini ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„±
            model = genai.GenerativeModel(self.model_name)
            response = model.generate_content(prompt)
            
            return response.text
            
        except Exception as e:
            print(f"âŒ Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# --- 5. í†µí•© ì±—ë´‡ í´ëž˜ìŠ¤ ---
class HWPChatbot:
    """HWP ë¬¸ì„œ ê¸°ë°˜ ì±—ë´‡"""
    
    def __init__(self, db_path=None):
        self.db_path = db_path or DB_PATH_SIMPLE
        self.searcher = HWPDocumentSearcher(self.db_path)
        self.generator = GeminiResponseGenerator()
        
        # ì´ˆê¸°í™” ìƒíƒœ í™•ì¸
        stats = self.searcher.get_statistics()
        if stats:
            print(f"âœ… ì±—ë´‡ ì´ˆê¸°í™” ì™„ë£Œ - ì´ {stats.get('total_documents', 0)}ê°œ ë¬¸ì„œ ë¡œë“œë¨")
        else:
            print("âš ï¸ ë¬¸ì„œ ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¹„ì–´ìžˆê±°ë‚˜ ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    def check_fixed_faq(self, query):
        """ê³ ì • FAQ í™•ì¸"""
        query_lower = query.lower()
        for keyword, answer in FIXED_FAQ_DATABASE.items():
            if keyword.lower() in query_lower:
                return answer
        return None
    
    def chat(self, query):
        """ë©”ì¸ ì±—ë´‡ ì‘ë‹µ í•¨ìˆ˜"""
        print(f"\nðŸ¤– ì‚¬ìš©ìž ì§ˆë¬¸: {query}")
        
        # 1. ê³ ì • FAQ í™•ì¸
        fixed_answer = self.check_fixed_faq(query)
        if fixed_answer:
            print("ðŸ“‹ ê³ ì • FAQ ì‘ë‹µ ì‚¬ìš©")
            return fixed_answer
        
        # 2. ë¬¸ì„œ ê²€ìƒ‰
        print("ðŸ” ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
        documents = self.searcher.search_documents(query, limit=5)
        
        if not documents:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì‹œê±°ë‚˜ ë‹´ë‹¹ ë¶€ì„œì— ì§ì ‘ ë¬¸ì˜í•˜ì‹œê¸° ë°”ëžë‹ˆë‹¤."
        
        print(f"ðŸ“„ {len(documents)}ê°œ ê´€ë ¨ ë¬¸ì„œ ë°œê²¬")
        
        # 3. AI ì‘ë‹µ ìƒì„±
        print("ðŸ¤– AI ì‘ë‹µ ìƒì„± ì¤‘...")
        response = self.generator.generate_response(query, documents)
        
        # 4. ì°¸ì¡° ë¬¸ì„œ ì •ë³´ ì¶”ê°€
        source_info = "\\n\\n**ì°¸ì¡° ë¬¸ì„œ:**\\n"
        for i, doc in enumerate(documents[:3], 1):
            filename = doc.meta.get('file_name', 'ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼')
            source_info += f"{i}. {filename}\\n"
        
        return response + source_info
    
    def get_status(self):
        """ì±—ë´‡ ìƒíƒœ ì •ë³´"""
        stats = self.searcher.get_statistics()
        return {
            "database_connected": self.searcher.conn is not None,
            "ai_available": self.generator.available,
            "total_documents": stats.get('total_documents', 0),
            "top_files": stats.get('top_files', [])
        }

# --- 6. í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ ---
def test_chatbot():
    """ì±—ë´‡ í…ŒìŠ¤íŠ¸"""
    chatbot = HWPChatbot()
    
    print("=" * 50)
    print("ðŸ¤– HWP ì±—ë´‡ í…ŒìŠ¤íŠ¸ ì‹œìž‘")
    print("=" * 50)
    
    # ìƒíƒœ í™•ì¸
    status = chatbot.get_status()
    print("ðŸ“Š ì±—ë´‡ ìƒíƒœ:")
    print(f"  - ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°: {status['database_connected']}")
    print(f"  - AI ì‚¬ìš© ê°€ëŠ¥: {status['ai_available']}")
    print(f"  - ì´ ë¬¸ì„œ ìˆ˜: {status['total_documents']}")
    print()
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    test_questions = [
        "ì—°ì°¨ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?",
        "íœ´ì§ ê´€ë ¨ ê·œì •ì´ ê¶ê¸ˆí•´ìš”",
        "ì¶œìž¥ ì‹ ì²­ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?",
        "ê¸‰ì—¬ ê´€ë ¨ ë¬¸ì˜ê°€ ìžˆìŠµë‹ˆë‹¤",
        "ì¸ì‚¬í‰ê°€ëŠ” ì–¸ì œ ì§„í–‰ë˜ë‚˜ìš”?"
    ]
    
    for question in test_questions:
        print(f"â“ ì§ˆë¬¸: {question}")
        answer = chatbot.chat(question)
        print(f"ðŸ¤– ë‹µë³€: {answer[:200]}..." if len(answer) > 200 else f"ðŸ¤– ë‹µë³€: {answer}")
        print("-" * 40)

if __name__ == "__main__":
    test_chatbot()