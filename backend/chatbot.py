import os
from haystack import Pipeline
# from haystack.components.generators import OpenAIGenerator  # OpenAI 
from haystack.components.embedders import SentenceTransformersTextEmbedder, SentenceTransformersDocumentEmbedder  # Using sentence transformers for embedding
from haystack.components.builders import PromptBuilder
from duckdb import DuckDBDocumentStore
from duckdb import DuckDBEmbeddingRetriever
from haystack.components.embedders import SentenceTransformersTextEmbedder
# from haystack.document_stores.in_memory import InMemoryDocumentStore
from haystack.components.preprocessors import DocumentSplitter
from haystack.components.converters import PyPDFToDocument
import google.generativeai as genai
from dotenv import load_dotenv

# --- 0. [í•„ìˆ˜] API í‚¤ ì„¤ì • ---
# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
load_dotenv()
google_api_key = os.getenv("GOOGLE_API_KEY")
if google_api_key:
    os.environ["GOOGLE_API_KEY"] = google_api_key
else:
    print("âš ï¸  ê²½ê³ : GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    # (API í‚¤ê°€ ì—†ì–´ë„ FAQ ê¸°ëŠ¥ì€ ì‘ë™í•©ë‹ˆë‹¤)

# --- 1. [ì‹ ê·œ] ê·œì¹™ ê¸°ë°˜ FAQ ë°ì´í„°ë² ì´ìŠ¤ (Req 1 & 2) ---
# ê¸°íšì•ˆì˜ "Quick Reply" ë° "FAQ ìë™ ì‘ë‹µ"ìš©
# í‚¤(Keyword)ê°€ ì§ˆë¬¸ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´, AI(RAG)ë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šê³  ì¦‰ì‹œ ì´ ë‹µë³€ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
# (í‚¤ì›Œë“œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì ì„ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤)
FIXED_FAQ_DATABASE = {
    "ì—°ì°¨ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?": "ì—°ì°¨ëŠ”... (ë¯¸ë¦¬ ì‘ì„±ëœ ê³ ì • ë‹µë³€)",
    "ë³µë¬´ ê·œì • ì•Œë ¤ì¤˜": "ë³µë¬´ ê·œì •ì€... (ë¯¸ë¦¬ ì‘ì„±ëœ ê³ ì • ë‹µë³€)",
    "ê²½ì¡°ì‚¬ íœ´ê°€": "ê²½ì¡°ì‚¬ íœ´ê°€ ê·œì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤...",
    "ì¶œì¥ ë³µëª…": "ì¶œì¥ ë³µëª…ì€ ê·¸ë£¹ì›¨ì–´ì˜ 'ê²°ì¬' ë©”ë‰´ì—ì„œ...",
    "ë²•ì¸ì¹´ë“œ ì‚¬ìš©": "ë²•ì¸ì¹´ë“œ ì‚¬ìš© ì§€ì¹¨ì€..."
    # (ì—¬ê¸°ì— 5ê°œì˜ Quick Reply ë° ì£¼ìš” FAQ í•­ëª©ì„ ëª¨ë‘ ì¶”ê°€í•˜ì„¸ìš”)
}
# --- 2. ê²½ë¡œ ë° ëª¨ë¸ ì„¤ì • ---
# (2) âœ¨ ì¤‘ìš”: build_index.pyì™€ ë™ì¼í•œ ëª¨ë¸/DB ê²½ë¡œ ì„¤ì •
EMBEDDING_MODEL = "jhgan/ko-sbert-nli"
DB_PATH = "hibot_store.db"
# --- 3. [ì‹ ê·œ] RAG íŒŒì´í”„ë¼ì¸ "ë¼ìš°í„°" (Req 3) ---

def initialize_chatbot():
    print("ì±—ë´‡ ì´ˆê¸°í™” ì¤‘...")
    
    # (A) ì˜êµ¬ ì €ì¥ì†Œ(DuckDB) ì—°ê²° (ì½ê¸° ì „ìš©)
    try:
        document_store = DuckDBDocumentStore(db_path=DB_PATH)
        print(f"âœ… '{DB_PATH}'ì—ì„œ {document_store.count_documents()}ê°œ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ '{DB_PATH}' DB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. {e}")
        print("ë¨¼ì € 'python build_index.py' ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ë¬¸ì„œë¥¼ ìƒ‰ì¸í•´ì£¼ì„¸ìš”.")
        return None

    # (B) RAG íŒŒì´í”„ë¼ì¸ ì¤€ë¹„ (ê¸°ì¡´ ì½”ë“œì™€ ìœ ì‚¬)
    text_embedder = SentenceTransformersTextEmbedder(model=EMBEDDING_MODEL)
    retriever = DuckDBEmbeddingRetriever(document_store=document_store, top_k=5)
    
    prompt_template = """
    ë‹¹ì‹ ì€ ì œê³µëœ [ë¬¸ì„œ] ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.
    ì˜¤ì§ [ë¬¸ì„œ]ì— ìˆëŠ” ë‚´ìš©ë§Œì„ ê·¼ê±°ë¡œ ì‚¬ìš©ìì˜ [ì§ˆë¬¸]ì— ëŒ€í•´ ëŒ€ë‹µí•´ì£¼ì„¸ìš”.
    [ë¬¸ì„œ]ì— ê´€ë ¨ ë‚´ìš©ì´ ì—†ë‹¤ë©´, "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ë¬¸ì„œì—ëŠ” ê´€ë ¨ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

    [ë¬¸ì„œ]:
    {% for doc in documents %}
      {{ doc.content }}
    {% endfor %}

    [ì§ˆë¬¸]: {{ question }}

    [ë‹µë³€]:
    """
    prompt_builder = PromptBuilder(template=prompt_template)
    
    # (C) ê²€ìƒ‰ ì „ìš© íŒŒì´í”„ë¼ì¸ êµ¬ì¶• (ìƒì„±ê¸°ëŠ” ë³„ë„ ì²˜ë¦¬)
    search_pipeline = Pipeline()
    search_pipeline.add_component("query_embedder", text_embedder)
    search_pipeline.add_component("retriever", retriever)
    search_pipeline.connect("query_embedder.embedding", "retriever.query_embedding")
    text_embedder.warm_up()
    
    print("âœ… ì±—ë´‡ RAG íŒŒì´í”„ë¼ì¸ ì¤€ë¹„ ì™„ë£Œ.")
    return search_pipeline, prompt_builder

def create_gemini_response(prompt):
    """Gemini APIë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (ê¸°ì¡´ ì½”ë“œ)"""
    try:
        genai.configure(api_key=os.environ.get("GOOGLE_API_KEY"))
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Gemini API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def ask_chatbot(question, search_pipeline, prompt_builder):
    """
    (âœ¨ ì‹ ê·œ ë¡œì§)
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„ì„œ FAQ(ê·œì¹™)ë¥¼ ë¨¼ì € í™•ì¸í•˜ê³ , 
    ì—†ìœ¼ë©´ RAG íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ "ë¼ìš°í„°"
    """
    print(f"\n[ì§ˆë¬¸] ğŸ’¬: {question}")
    
    # --- 1ë‹¨ê³„: ê·œì¹™ ê¸°ë°˜ FAQ í™•ì¸ (Req 1 & 2) ---
    # ê¸°íšì•ˆì˜ "í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€" ë¡œì§
    for keyword, answer in FIXED_FAQ_DATABASE.items():
        if keyword in question:
            print(f"[ë‹µë³€] ğŸ¤– (ê·œì¹™ ê¸°ë°˜ FAQ): {answer}")
            return answer

    # --- 2ë‹¨ê³„: RAG + LLM ì‘ë‹µ (Req 3) ---
    print("(ê·œì¹™ ê¸°ë°˜ ë‹µë³€ ì—†ìŒ. RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰...)")
    try:
        # (A) ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        search_result = search_pipeline.run({"query_embedder": {"text": question}})
        retrieved_docs = search_result["retriever"]["documents"]
        
        if not retrieved_docs:
            print("[ë‹µë³€] ğŸ¤– (RAG): ì£„ì†¡í•©ë‹ˆë‹¤. ë¬¸ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ë¬¸ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        # (B) í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt_result = prompt_builder.run(documents=retrieved_docs, question=question)
        full_prompt = prompt_result["prompt"]
        
        # (C) Gemini APIë¡œ ë‹µë³€ ìƒì„±
        answer = create_gemini_response(full_prompt)
        print(f"[ë‹µë³€] ğŸ¤– (AI ìƒì„±): {answer}")
        return answer
        
    except Exception as e:
        error_msg = f"ì±—ë´‡ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        print(f"[ì˜¤ë¥˜] âŒ: {error_msg}")
        return error_msg

# --- 4. ì±—ë´‡ ì‹¤í–‰ ---
if __name__ == "__main__":
    # ì±—ë´‡ íŒŒì´í”„ë¼ì¸ 1íšŒ ì´ˆê¸°í™”
    pipeline_components = initialize_chatbot()
    
    if pipeline_components:
        search_pipeline, prompt_builder = pipeline_components
        
        # (í…ŒìŠ¤íŠ¸)
        
        # (1) FAQ ì§ˆë¬¸ (RAG ë¯¸ì‚¬ìš©)
        ask_chatbot("ì—°ì°¨ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?", search_pipeline, prompt_builder)
        
        # (2) ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ (RAG ì‚¬ìš©)
        ask_chatbot("ì‘ë…„ë„ ë³µë¬´ ê·œì • ìš”ì•½í•´ì¤˜.", search_pipeline, prompt_builder)
        
        # (3) ë¬¸ì„œì— ì—†ëŠ” ì§ˆë¬¸ (RAG ì‚¬ìš© -> ì‹¤íŒ¨ ì‘ë‹µ)
        ask_chatbot("í•˜ëŠ˜ì€ ì™œ íŒŒë€ê°€ìš”?", search_pipeline, prompt_builder)