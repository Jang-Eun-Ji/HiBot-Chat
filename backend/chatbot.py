import os
import pickle
import duckdb
import json
import numpy as np
from haystack import Pipeline
from haystack.components.embedders import SentenceTransformersTextEmbedder, SentenceTransformersDocumentEmbedder
from haystack.components.builders import PromptBuilder
from haystack.dataclasses import Document
from haystack.components.preprocessors import DocumentSplitter
from haystack.components.converters import PyPDFToDocument
import google.generativeai as genai
from dotenv import load_dotenv

# --- 0. [í•„ìˆ˜] API í‚¤ ì„¤ì • ---
# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
load_dotenv()
google_api_key = os.getenv("GOOGLE_API_KEY")
if google_api_key:
    os.environ["GOOGLE_API_KEY"] = google_api_key
else:
    print("âš ï¸  ê²½ê³ : GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    # (API í‚¤ê°€ ì—†ì–´ë„ FAQ ê¸°ëŠ¥ì€ ì‘ë™í•©ë‹ˆë‹¤)

# --- 1. [ì‹ ê·œ] ê·œì¹™ ê¸°ë°˜ FAQ ë°ì´í„°ë² ì´ìŠ¤ (Req 1 & 2) ---
# ê¸°íšì•ˆì˜ "Quick Reply" ë° "FAQ ìë™ ì‘ë‹µ"ìš©
# í‚¤(Keyword)ê°€ ì§ˆë¬¸ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´, AI(RAG)ë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šê³  ì¦‰ì‹œ ì´ ë‹µë³€ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
# (í‚¤ì›Œë“œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì ì„ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤)
FIXED_FAQ_DATABASE = {
    "ì—°ì°¨ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?": "ì—°ì°¨ëŠ”... (ë¯¸ë¦¬ ì‘ì„±ëœ ê³ ì • ë‹µë³€)",
    "ë³µë¬´ ê·œì • ì•Œë ¤ì¤˜": "ë³µë¬´ ê·œì •ì€... (ë¯¸ë¦¬ ì‘ì„±ëœ ê³ ì • ë‹µë³€)",
    "ê²½ì¡°ì‚¬ íœ´ê°€": "ê²½ì¡°ì‚¬ íœ´ê°€ ê·œì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤...",
    "ì¶œì¥ ë³µëª…": "ì¶œì¥ ë³µëª…ì€ ê·¸ë£¹ì›¨ì–´ì˜ 'ê²°ì¬' ë©”ë‰´ì—ì„œ...",
    "ë²•ì¸ì¹´ë“œ ì‚¬ìš©": "ë²•ì¸ì¹´ë“œ ì‚¬ìš© ì§€ì¹¨ì€..."
    # (ì—¬ê¸°ì— 5ê°œì˜ Quick Reply ë° ì£¼ìš” FAQ í•­ëª©ì„ ëª¨ë‘ ì¶”ê°€í•˜ì„¸ìš”)
}
# --- 2. ê²½ë¡œ ë° ëª¨ë¸ ì„¤ì • ---
# (2) âœ¨ ì¤‘ìš”: build_index.pyì™€ ë™ì¼í•œ ëª¨ë¸/ì €ì¥ì†Œ ê²½ë¡œ ì„¤ì •
# EMBEDDING_MODEL = "all-MiniLM-L6-v2"  # build_index.pyì™€ ë™ì¼í•œ ëª¨ë¸ ì‚¬ìš©
EMBEDDING_MODEL = "jhgan/ko-sbert-nli"  # í•œêµ­ì–´ ëª¨ë¸ (SSL ë¬¸ì œ í•´ê²° í›„ ì‚¬ìš©)
DB_PATH = "hibot_store.db"  # build_index.pyì™€ ë™ì¼í•œ DuckDB íŒŒì¼ ê²½ë¡œ

# --- 3. Custom DuckDB Retriever Class ---
class DuckDBEmbeddingRetriever:
    """DuckDBì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ì»¤ìŠ¤í…€ ë¦¬íŠ¸ë¦¬ë²„"""
    
    def __init__(self, db_path, top_k=5):
        self.db_path = db_path
        self.top_k = top_k
        self.conn = None
        
    def connect(self):
        """DuckDB ì—°ê²°"""
        if self.conn is None:
            self.conn = duckdb.connect(self.db_path)
    
    def run(self, query_embedding):
        """ì¿¼ë¦¬ ì„ë² ë”©ê³¼ ìœ ì‚¬í•œ ë¬¸ì„œë“¤ì„ ê²€ìƒ‰"""
        self.connect()
        
        # ëª¨ë“  ë¬¸ì„œì™€ ì„ë² ë”©ì„ ê°€ì ¸ì˜´
        docs_data = self.conn.execute("""
            SELECT id, content, meta, embedding 
            FROM documents 
            WHERE embedding IS NOT NULL
        """).fetchall()
        
        if not docs_data:
            return {"documents": []}
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = []
        for doc_id, content, meta_str, embedding in docs_data:
            if embedding:
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                doc_embedding = np.array(embedding)
                query_emb = np.array(query_embedding[0])  # query_embedding is a list
                
                similarity = np.dot(query_emb, doc_embedding) / (
                    np.linalg.norm(query_emb) * np.linalg.norm(doc_embedding)
                )
                
                try:
                    meta = json.loads(meta_str) if meta_str else {}
                except:
                    meta = {}
                
                similarities.append((similarity, doc_id, content, meta))
        
        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  top_kë§Œ ì„ íƒ
        similarities.sort(reverse=True, key=lambda x: x[0])
        top_docs = similarities[:self.top_k]
        
        # Document ê°ì²´ ìƒì„±
        documents = []
        for similarity, doc_id, content, meta in top_docs:
            doc = Document(id=doc_id, content=content, meta=meta)
            documents.append(doc)
        
        return {"documents": documents}
# --- 4. [ì‹ ê·œ] RAG íŒŒì´í”„ë¼ì¸ "ë¼ìš°í„°" (Req 3) ---

def initialize_chatbot():
    print("ì±—ë´‡ ì´ˆê¸°í™” ì¤‘...")
    
    # (A) DuckDB ì—°ê²° í™•ì¸
    try:
        if not os.path.exists(DB_PATH):
            print(f"âŒ '{DB_PATH}' ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ë¨¼ì € 'python build_index.py' ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ë¬¸ì„œë¥¼ ìƒ‰ì¸í•´ì£¼ì„¸ìš”.")
            return None
            
        conn = duckdb.connect(DB_PATH)
        doc_count = conn.execute("SELECT COUNT(*) FROM documents").fetchone()[0]
        conn.close()
        print(f"âœ… '{DB_PATH}'ì—ì„œ {doc_count}ê°œ ë¬¸ì„œë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ '{DB_PATH}' ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        print("ë¨¼ì € 'python build_index.py' ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ë¬¸ì„œë¥¼ ìƒ‰ì¸í•´ì£¼ì„¸ìš”.")
        return None

    # (B) RAG íŒŒì´í”„ë¼ì¸ ì¤€ë¹„ (SSL ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨)
    try:
        text_embedder = SentenceTransformersTextEmbedder(model=EMBEDDING_MODEL)
        retriever = DuckDBEmbeddingRetriever(db_path=DB_PATH, top_k=5)
        print("âœ… ì„ë² ë”ì™€ ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ì„ë² ë” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("ğŸ“‹ í•´ê²°ë°©ë²•:")
        print("   1. pip install --upgrade certifi")
        print("   2. ì¸í„°ë„· ì—°ê²° í™•ì¸")
        return None
    
    prompt_template = """
    ë‹¹ì‹ ì€ ì œê³µëœ [ë¬¸ì„œ] ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.
    ì˜¤ì§ [ë¬¸ì„œ]ì— ìˆëŠ” ë‚´ìš©ë§Œì„ ê·¼ê±°ë¡œ ì‚¬ìš©ìì˜ [ì§ˆë¬¸]ì— ëŒ€í•´ ëŒ€ë‹µí•´ì£¼ì„¸ìš”.
    [ë¬¸ì„œ]ì— ê´€ë ¨ ë‚´ìš©ì´ ì—†ë‹¤ë©´, "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ë¬¸ì„œì—ëŠ” ê´€ë ¨ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

    [ë¬¸ì„œ]:
    {% for doc in documents %}
      {{ doc.content }}
    {% endfor %}

    [ì§ˆë¬¸]: {{ question }}

    [ë‹µë³€]:
    """
    prompt_builder = PromptBuilder(template=prompt_template, required_variables=["documents", "question"])
    
    # (C) ì„ë² ë” ì´ˆê¸°í™” (SSL ì˜¤ë¥˜ ì²˜ë¦¬)
    try:
        # ì„ë² ë” ì´ˆê¸°í™” (SSL ì˜¤ë¥˜ ì²˜ë¦¬)
        text_embedder.warm_up()
        print("âœ… ì±—ë´‡ RAG íŒŒì´í”„ë¼ì¸ ì¤€ë¹„ ì™„ë£Œ.")
        return text_embedder, retriever, prompt_builder
    except Exception as e:
        print(f"âŒ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None

def create_gemini_response(prompt):
    """Gemini APIë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (ê¸°ì¡´ ì½”ë“œ)"""
    try:
        genai.configure(api_key=os.environ.get("GOOGLE_API_KEY"))
        model = genai.GenerativeModel('gemini-1.5-pro')  # Updated model name
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Gemini API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def ask_chatbot(question, text_embedder, retriever, prompt_builder):
    """
    (âœ¨ ì‹ ê·œ ë¡œì§)
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„ì„œ FAQ(ê·œì¹™)ë¥¼ ë¨¼ì € í™•ì¸í•˜ê³ , 
    ì—†ìœ¼ë©´ RAG íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ "ë¼ìš°í„°"
    """
    print(f"\n[ì§ˆë¬¸] ğŸ’¬: {question}")
    
    # --- 1ë‹¨ê³„: ê·œì¹™ ê¸°ë°˜ FAQ í™•ì¸ (Req 1 & 2) ---
    # ê¸°íšì•ˆì˜ "í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€" ë¡œì§
    for keyword, answer in FIXED_FAQ_DATABASE.items():
        if keyword in question:
            print(f"[ë‹µë³€] ğŸ¤– (ê·œì¹™ ê¸°ë°˜ FAQ): {answer}")
            return answer

    # --- 2ë‹¨ê³„: RAG + LLM ì‘ë‹µ (Req 3) ---
    print("(ê·œì¹™ ê¸°ë°˜ ë‹µë³€ ì—†ìŒ. RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰...)")
    try:
        # (A) ì§ˆë¬¸ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
        query_embedding_result = text_embedder.run(text=question)
        query_embedding = query_embedding_result["embedding"]
        
        # (B) ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        retrieved_docs = retriever.run(query_embedding=[query_embedding])["documents"]
        
        if not retrieved_docs:
            print("[ë‹µë³€] ğŸ¤– (RAG): ì£„ì†¡í•©ë‹ˆë‹¤. ë¬¸ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ë¬¸ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        # (C) í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt_result = prompt_builder.run(documents=retrieved_docs, question=question)
        full_prompt = prompt_result["prompt"]
        
        # (D) Gemini APIë¡œ ë‹µë³€ ìƒì„±
        answer = create_gemini_response(full_prompt)
        print(f"[ë‹µë³€] ğŸ¤– (AI ìƒì„±): {answer}")
        return answer
        
    except Exception as e:
        error_msg = f"ì±—ë´‡ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        print(f"[ì˜¤ë¥˜] âŒ: {error_msg}")
        return error_msg

# --- 5. ì±—ë´‡ ì‹¤í–‰ ---
if __name__ == "__main__":
    # ì±—ë´‡ íŒŒì´í”„ë¼ì¸ 1íšŒ ì´ˆê¸°í™”
    pipeline_components = initialize_chatbot()
    
    if pipeline_components:
        text_embedder, retriever, prompt_builder = pipeline_components
        
        # (í…ŒìŠ¤íŠ¸)
        
        # (1) FAQ ì§ˆë¬¸ (RAG ë¯¸ì‚¬ìš©)
        ask_chatbot("ì—°ì°¨ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?", text_embedder, retriever, prompt_builder)
        
        # (2) ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ (RAG ì‚¬ìš©)
        ask_chatbot("ì‘ë…„ë„ ë³µë¬´ ê·œì • ìš”ì•½í•´ì¤˜.", text_embedder, retriever, prompt_builder)
        
        # (3) ë¬¸ì„œì— ì—†ëŠ” ì§ˆë¬¸ (RAG ì‚¬ìš© -> ì‹¤íŒ¨ ì‘ë‹µ)
        ask_chatbot("í•˜ëŠ˜ì€ ì™œ íŒŒë€ê°€ìš”?", text_embedder, retriever, prompt_builder)