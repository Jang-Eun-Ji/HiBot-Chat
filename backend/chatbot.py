import os
import duckdb
import json
import numpy as np
from haystack.components.embedders import SentenceTransformersTextEmbedder
from haystack.components.builders import PromptBuilder
from haystack.dataclasses import Document
import google.generativeai as genai
from dotenv import load_dotenv

from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware


# --- 2. ê²½ë¡œ ë° ëª¨ë¸ ì„¤ì • ---
# EMBEDDING_MODEL = "all-MiniLM-L6-v2"  # build_index.pyì™€ ë™ì¼í•œ ëª¨ë¸ ì‚¬ìš©
EMBEDDING_MODEL = "jhgan/ko-sbert-nli"  # í•œêµ­ì–´ ëª¨ë¸ (SSL ë¬¸ì œ í•´ê²° í›„ ì‚¬ìš©)
DB_PATH = "hibot_store.db"  # build_index.pyì™€ ë™ì¼í•œ DuckDB íŒŒì¼ ê²½ë¡œ
# KEYWORD_FILE = "document_keywords.json" # ë¬¸ì„œ í‚¤ì›Œë“œ ë§¤í•‘ íŒŒì¼ ê²½ë¡œ
SYNONYM_MAP_PATH = "synonym_map.json" # ë™ì˜ì–´ íŒŒì¼ ê²½ë¡œ 
EMPLOYEE_JSON_PATH = "employee_roles.json" # ì§ì› ì—­í•  ì •ë³´ íŒŒì¼ ê²½ë¡œ

text_embedder = None
retriever = None
prompt_builder = None



# --- 0. [í•„ìˆ˜] API í‚¤ ì„¤ì • ---
# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

google_api_key = os.getenv("GOOGLE_API_KEY")
if google_api_key:
    os.environ["GOOGLE_API_KEY"] = google_api_key
else:
    print("âš ï¸  ê²½ê³ : GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    # (API í‚¤ê°€ ì—†ì–´ë„ FAQ ê¸°ëŠ¥ì€ ì‘ë™í•©ë‹ˆë‹¤)

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],      # ëª¨ë“  ë„ë©”ì¸ í—ˆìš©
    allow_credentials=True,  
    allow_methods=["*"],      # ëª¨ë“  HTTP ë©”ì„œë“œ í—ˆìš©
    allow_headers=["*"],      # ëª¨ë“  í—¤ë” í—ˆìš©
)

# --- 1. [ì‹ ê·œ] ê·œì¹™ ê¸°ë°˜ FAQ ë°ì´í„°ë² ì´ìŠ¤ (Req 1 & 2) ---
# ê¸°íšì•ˆì˜ "Quick Reply" ë° "FAQ ìë™ ì‘ë‹µ"ìš©
# í‚¤(Keyword)ê°€ ì§ˆë¬¸ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´, AI(RAG)ë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šê³  ì¦‰ì‹œ ì´ ë‹µë³€ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
# (í‚¤ì›Œë“œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì ì„ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤)
# --- 1. ìˆœì„œ ê¸°ë°˜ FAQ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€ê²½ ---
FIXED_FAQ_DATABASE = [
    "[ì¸ì‚¬ê·¼íƒœ(í™•ì¥)] â†’ [ì‹œê°„ì™¸ê·¼ë¬´] â†’ [ì‹œê°„ì™¸ê·¼ë¬´ ì‹ ì²­ê´€ë¦¬] ë©”ë‰´ì—ì„œ ì‹ ì²­ ê°€ëŠ¥í•©ë‹ˆë‹¤. 1ì¼ ìµœëŒ€ 3ì‹œê°„ 30ë¶„, ì›” ìµœëŒ€ 15ì‹œê°„ê¹Œì§€ ì‹ ì²­ ê°€ëŠ¥í•˜ë©°, íœ´ê²Œì‹œê°„ 30ë¶„ì„ ì œì™¸í•´ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤. \n\nğŸ“„ ì¶œì²˜: [á„á…¥á†«á„á…¦á†«á„á…³1] á„€á…§á†¼á„‹á…§á†¼á„Œá…µá„‹á…¯á†« á„‹á…¥á†¸á„†á…® á„Œá…µá†¯á„‹á…´á„‹á…³á†¼á„ƒá…¡á†¸(Q&A)_202509_á„€á…©á†¼á„€á…¢á„‹á…­á†¼ ",
    "ê¸‰ì—¬ ë‹´ë‹¹ì ì´ë©”ì¼ë¡œ ê°€ì¡±ìˆ˜ë‹¹ ì‹ ì²­ì„œì™€ ì¦ë¹™ì„œë¥˜(ê°€ì¡±ê´€ê³„ì¦ëª…ì„œ, ê±´ê°•ë³´í—˜ ìê²©í™•ì¸ì„œ ë“±)ë¥¼ ì œì¶œí•˜ë©´ ë©ë‹ˆë‹¤. ë°°ìš°ì 4ë§Œì›, ì§ê³„ì¡´ì†Â·ë¹„ì† ê° 3ë§Œì›ì´ ì§€ê¸‰ë©ë‹ˆë‹¤. â€» ê´€ë ¨ê·¼ê±°: ë³´ìˆ˜ê·œì • ì‹œí–‰ê·œì¹™ ë³„í‘œ ì œ1í˜¸ \n\nğŸ“„ ì¶œì²˜: [á„á…¥á†«á„á…¦á†«á„á…³1] á„€á…§á†¼á„‹á…§á†¼á„Œá…µá„‹á…¯á†« á„‹á…¥á†¸á„†á…® á„Œá…µá†¯á„‹á…´á„‹á…³á†¼á„ƒá…¡á†¸(Q&A)_202509_á„€á…©á†¼á„€á…¢á„‹á…­á†¼",
    "ì •ê·œì§Â·ê³„ì•½ì§ ì§ì›ì—ê²Œ ì—°ê°„ 1,000,000í¬ì¸íŠ¸(1P=1ì›)ê°€ ë¶€ì—¬ë˜ë©°, ë‹¨ì²´ë³´í—˜ë£Œ ê³µì œ í›„ ì”ì•¡ í•œë„ ë‚´ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. ì…Â·í‡´ì‚¬ìëŠ” ê·¼ë¬´ê¸°ê°„ì— ë”°ë¼ ì›”í•  ê³„ì‚° ì ìš©ë©ë‹ˆë‹¤. \n\nğŸ“„ ì¶œì²˜: [á„á…¥á†«á„á…¦á†«á„á…³1] á„€á…§á†¼á„‹á…§á†¼á„Œá…µá„‹á…¯á†« á„‹á…¥á†¸á„†á…® á„Œá…µá†¯á„‹á…´á„‹á…³á†¼á„ƒá…¡á†¸(Q&A)_202509_á„€á…©á†¼á„€á…¢á„‹á…­á†¼",
    "ì¶œì¥ì‹ ì²­ì€ [ì¸ì‚¬ê·¼íƒœ(í™•ì¥)] â†’ [ê·¼íƒœì‹ ì²­ì„œ] â†’ [ì¶œì¥ì‹ ì²­] ë©”ë‰´ì—ì„œ ê°€ëŠ¥í•©ë‹ˆë‹¤. êµ­ë‚´ì¶œì¥ì€ 1ì£¼ì¼ ì´ë‚´, êµ­ì™¸ì¶œì¥ì€ 2ì£¼ì¼ ì´ë‚´ì— ìš´ì„Â·ìˆ™ë°•ë¹„ ë“± ì¦ë¹™ì„œë¥˜ë¥¼ ì²¨ë¶€í•˜ì—¬ ì •ì‚°í•´ì•¼ í•©ë‹ˆë‹¤. \n\nğŸ“„ ì¶œì²˜: [á„á…¥á†«á„á…¦á†«á„á…³1] á„€á…§á†¼á„‹á…§á†¼á„Œá…µá„‹á…¯á†« á„‹á…¥á†¸á„†á…® á„Œá…µá†¯á„‹á…´á„‹á…³á†¼á„ƒá…¡á†¸(Q&A)_202509_á„€á…©á†¼á„€á…¢á„‹á…­á†¼",
    "ì „ì‚°ê¸°ê¸° ë° ì‚¬ë¬´ê¸°ê¸°(PC, ë³µí•©ê¸°, ì„¸ë‹¨ê¸° ë“±)ëŠ” ê¸°ê¸° ì¤‘ê°„ ë˜ëŠ” í•˜ë‹¨ì— ë¶€ì°©ëœ ìˆ˜ë¦¬ê¸°ì‚¬ ì—°ë½ì²˜ë¡œ ì§ì ‘ ìœ ì„  ë¬¸ì˜í•˜ì‹œë©´ ë©ë‹ˆë‹¤. ê¸°íƒ€ ì‹œì„¤ë¬¼(ì¡°ëª…, ì˜ì, ë¬¸ì†ì¡ì´ ë“±) ê³ ì¥ì€ ê²½ì˜ì§€ì›ë¶€ ë¬¼í’ˆê´€ë¦¬ ë‹´ë‹¹ìì—ê²Œ ì—°ë½í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n\nğŸ“„ ì¶œì²˜: [á„á…¥á†«á„á…¦á†«á„á…³1] á„€á…§á†¼á„‹á…§á†¼á„Œá…µá„‹á…¯á†« á„‹á…¥á†¸á„†á…® á„Œá…µá†¯á„‹á…´á„‹á…³á†¼á„ƒá…¡á†¸(Q&A)_202509_á„€á…©á†¼á„€á…¢á„‹á…­á†¼"
]

FAQ_KEYWORDS = [
    ["ì‹œê°„ì™¸ê·¼ë¬´", "ì‹œê°„ ì™¸ ê·¼ë¬´", "ì—°ì¥ê·¼ë¬´"],
    ["ê°€ì¡±ìˆ˜ë‹¹", "ê°€ì¡± ìˆ˜ë‹¹"],
    ["ë³µì§€í¬ì¸íŠ¸", "ë³µì§€ í¬ì¸íŠ¸"],
    ["ì¶œì¥", "ì—¬ë¹„ì •ì‚°", "ì •ì‚°"],
    ["ì „ì‚°ì¥ë¹„", "PC", "í”„ë¦°í„°", "ì‹œì„¤ë¬¼", "ê³ ì¥"]
]

# employee_roles.json ë¡œë”© í•¨ìˆ˜
def load_employee_roles():
    try:
        with open(EMPLOYEE_JSON_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"âš ï¸ employee_roles.json ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return []

EMPLOYEES = load_employee_roles()

def find_best_employee(question: str):
    """
    ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ê´€ë ¨ ìˆëŠ” ì§ì› ì¶”ì²œ
    ë§¤ì¹­ ì ìˆ˜ ê¸°ì¤€:
    - ì§ˆë¬¸ í‚¤ì›Œë“œê°€ ì—…ë¬´(task)ì— ë“±ì¥í•˜ë©´ +1
    """
    if not EMPLOYEES:
        return None

    # ì§ˆë¬¸ì„ ë‹¨ì–´ë¡œ ë¶„ë¦¬
    keywords = [w for w in question.split() if len(w) >= 2]

    best_match = None
    best_score = 0

    for emp in EMPLOYEES:
        score = 0
        for task in emp["tasks"]:
            for kw in keywords:
                if kw in task:
                    score += 1

        if score > best_score:
            best_score = score
            best_match = emp

    return best_match


# ë™ì˜ì–´ ë§µ ë¡œë“œ í•¨ìˆ˜
def load_synonym_map():
    try:
        with open(SYNONYM_MAP_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"âš ï¸ synonym_map.json ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return {}

SYNONYM_MAP = load_synonym_map()

# ê¸´ ë¬¸ì„œë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ëŠ” í•¨ìˆ˜
# def smart_trim(text, max_length=600):
#     if not text:
#         return ""

#     if len(text) <= max_length:
#         return text

#     trimmed = text[:max_length]

#     # ì—¬ëŸ¬ í›„ë³´ ë¬¸ì¥ë¶€í˜¸ ê²€ìƒ‰
#     end_marks = ['ë‹¤.', 'ìš”.', 'í•¨.', '.', '!', '?', '\n']

#     last_cut = -1
#     for mark in end_marks:
#         pos = trimmed.rfind(mark)
#         if pos != -1:
#             end_pos = pos + len(mark)
#             if end_pos > last_cut:
#                 last_cut = end_pos

#     # ë¬¸ì¥ë¶€í˜¸ ì°¾ì€ ê²½ìš°
#     if last_cut != -1:
#         return trimmed[:last_cut]

#     # ë¬¸ì¥ë¶€í˜¸ ì—†ìœ¼ë©´ ë‹¨ì–´ ê¸°ì¤€ìœ¼ë¡œ ìë¦„
#     last_space = trimmed.rfind(" ")
#     if last_space != -1:
#         return trimmed[:last_space]

#     return trimmed



# --- 3. ì§ˆë¬¸ê³¼ ë¹„ìŠ·í•œ ë¬¸ì„œë¥¼ DuckDBì—ì„œ ì°¾ì•„ì£¼ëŠ” ê²€ìƒ‰ ì—”ì§„ ---
class DuckDBEmbeddingRetriever:
    """
    DuckDB ê¸°ë°˜ semantic search retriever
    âœ” top_k ê°œìˆ˜ ì œí•œ
    âœ” similarity threshold ì ìš©
    âœ” similarity ì •ë³´ metaì— ì €ì¥
    âœ” ì˜ˆì˜ê²Œ ë¡œê·¸ ì¶œë ¥
    """

    def __init__(self, db_path, top_k=6, threshold=0.5):
        self.db_path = db_path
        self.top_k = top_k
        self.threshold = threshold
        self.conn = None
        
    def connect(self):
        if self.conn is None:
            self.conn = duckdb.connect(self.db_path)


    def run(self, query_embedding):
        """query_embedding(list) â†’ DuckDBì—ì„œ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        self.connect()

        # ëª¨ë“  ë¬¸ì„œ ë¡œë“œ
        docs_data = self.conn.execute("""
            SELECT id, content, meta, embedding 
            FROM documents 
            WHERE embedding IS NOT NULL
        """).fetchall()

        if not docs_data:
            return {"documents": []}

        query_emb = np.array(query_embedding[0])
        similarities = []

        print("\nğŸ“˜ [DuckDB Retriever] ë¬¸ì„œ ìœ ì‚¬ë„ ê³„ì‚° ì‹œì‘")
        print(f" - Threshold = {self.threshold}")
        print(" - --------------------------------------------")

        # ê° ë¬¸ì„œì™€ similarity ê³„ì‚°
        for doc_id, content, meta_str, embedding in docs_data:
            if not embedding:
                continue

            doc_emb = np.array(embedding)

            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarity = float(
                np.dot(query_emb, doc_emb) 
                / (np.linalg.norm(query_emb) * np.linalg.norm(doc_emb))
            )

            # ë©”íƒ€ ë¡œë“œ
            try:
                meta = json.loads(meta_str) if meta_str else {}
            except:
                meta = {}

            file_name = meta.get("file_name", "ì•Œ ìˆ˜ ì—†ìŒ")
            page = meta.get("page_number", "N/A")

            # ì˜ˆìœ ë¡œê·¸ ì¶œë ¥
            print(f"ğŸ” ë¬¸ì„œ: {file_name} (p.{page}) â†’ ìœ ì‚¬ë„: {similarity:.4f}")

            # threshold ë¯¸ë‹¬ â†’ ê±´ë„ˆë›°ê¸°
            if similarity < self.threshold:
                continue

            similarities.append((similarity, doc_id, content, meta))

        print(" - --------------------------------------------")

        # threshold ë¯¸ë‹¬ ë¬¸ì„œë§Œ ìˆì—ˆë‹¤ë©´
        if not similarities:
            print("âŒ threshold ì´ìƒ ë¬¸ì„œ ì—†ìŒ â†’ ë¬¸ì„œ ì—†ìŒìœ¼ë¡œ ì²˜ë¦¬ë¨")
            return {"documents": []}

        # ìƒìœ„ top_kë§Œ ì„ íƒ
        similarities.sort(reverse=True, key=lambda x: x[0])
        top_docs = similarities[:self.top_k]

        # Document ê°ì²´ ìƒì„±
        documents = []
        print("\nğŸ“˜ ìµœì¢… ì„ íƒëœ ë¬¸ì„œ(top_k)")
        for similarity, doc_id, content, meta in top_docs:
            meta["similarity"] = similarity
            print(f"âœ” {meta.get('file_name', 'ì•Œ ìˆ˜ ì—†ìŒ')} â†’ {similarity:.4f}")
            documents.append(Document(id=doc_id, content=content, meta=meta))

        print("------------------------------------------------\n")

        return {"documents": documents}

    

def find_representative_keyword(question: str):
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— SYNONYM_MAPì˜ ë™ì˜ì–´ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ 
    ëŒ€í‘œ í‚¤ì›Œë“œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    ì˜ˆ: 'ì•¼ê·¼ ì‹ ì²­ ì–´ë–»ê²Œ?' â†’ 'ì‹œê°„ì™¸ê·¼ë¬´'
    """
    for rep_keyword, synonyms in SYNONYM_MAP.items():
        # ëŒ€í‘œ ë‹¨ì–´ ìì²´ê°€ ì§ˆë¬¸ì— ìˆëŠ” ê²½ìš°
        if rep_keyword in question:
            return rep_keyword
        
        # ë™ì˜ì–´ë“¤ì´ ì§ˆë¬¸ ì•ˆì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€
        for syn in synonyms:
            if syn in question:
                return rep_keyword

    return None



# --- 4. [ì‹ ê·œ] RAG íŒŒì´í”„ë¼ì¸ "ë¼ìš°í„°" (Req 3) ---

def initialize_chatbot():
    print("ì±—ë´‡ ì´ˆê¸°í™” ì¤‘...")
    
    # (A) DuckDB ì—°ê²° í™•ì¸
    try:
        if not os.path.exists(DB_PATH):
            print(f"âŒ '{DB_PATH}' ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ë¨¼ì € 'python build_index.py' ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ë¬¸ì„œë¥¼ ìƒ‰ì¸í•´ì£¼ì„¸ìš”.")
            return None
        
        conn = duckdb.connect(DB_PATH)
        doc_count = conn.execute("SELECT COUNT(*) FROM documents").fetchone()[0]
        conn.close()
        print(f"âœ… '{DB_PATH}'ì—ì„œ {doc_count}ê°œ ë¬¸ì„œë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ '{DB_PATH}' ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        print("ë¨¼ì € 'python build_index.py' ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ë¬¸ì„œë¥¼ ìƒ‰ì¸í•´ì£¼ì„¸ìš”.")
        return None

    # (B) RAG íŒŒì´í”„ë¼ì¸ ì¤€ë¹„ (SSL ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨)
    try:
        # í•œêµ­ì–´ ë¬¸ì¥ì„ ìˆ«ì ë²¡í„°ë¡œ ìë™ ë³€í™˜í•´ì£¼ëŠ” ëª¨ë¸ì„ ë¡œë”© 
        text_embedder = SentenceTransformersTextEmbedder(model=EMBEDDING_MODEL)
        # ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰ê¸°(semantic search engine)
        # DuckDB íŒŒì¼(hibot_store.db)ì— ì ‘ì†í•´ì„œ ë¬¸ì„œë“¤ì˜ ì„ë² ë”©(vector) ëª©ë¡ì„ ì½ê³  
        # ì§ˆë¬¸ì˜  ì„ë² ë”©ê³¼ ì½”ì‚¬ì¸ ìœ ì‚¬ë„(similarity score)ë¥¼ ê³„ì‚°í•´ì„œ ê°€ì¥ ë¹„ìŠ·í•œ ë¬¸ì„œ **12(top_k=12)**ë¥¼ ë°˜í™˜í•¨
        retriever = DuckDBEmbeddingRetriever(db_path=DB_PATH, top_k=6)
        print("âœ… ì„ë² ë”ì™€ ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ì„ë² ë” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("ğŸ“‹ í•´ê²°ë°©ë²•:")
        print("   1. pip install --upgrade certifi")
        print("   2. ì¸í„°ë„· ì—°ê²° í™•ì¸")
        return None
    
    prompt_template = """
ë‹¹ì‹ ì€ ë‚´ë¶€ ê·œì •Â·ì§€ì¹¨Â·ì—…ë¬´ ë§¤ë‰´ì–¼ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì•„ë˜ [ì°¸ê³  ë¬¸ì„œ]ëŠ” ì§ˆë¬¸ê³¼ ê°€ì¥ ì—°ê´€ì„±ì´ ë†’ì€ ë¬¸ì„œë“¤ì…ë‹ˆë‹¤. ì§ˆë¬¸ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ë¬¸ì„œë¥¼ [ì°¸ê³  ë¬¸ì„œ]ë¥¼ ì •ë¦¬ í•´ì„œ ë‹µë³€í•´ ì£¼ì„¸ìš”.

[ì°¸ê³  ë¬¸ì„œ]
{% for doc in documents %}
ë¬¸ì„œ {{ loop.index }}:
- íŒŒì¼ëª…: {{ doc.meta.file_name }}
- ìœ ì‚¬ë„: {{ doc.meta.similarity }}
- ë‚´ìš©:
{{ doc.content }}
{% endfor %}

[ì§ˆë¬¸]: {{ question }}

[ë‹µë³€]:
"""
    prompt_builder = PromptBuilder(template=prompt_template, required_variables=["documents", "question"])
    
    # (C) ì„ë² ë” ì´ˆê¸°í™” (SSL ì˜¤ë¥˜ ì²˜ë¦¬)
    try:
        # ì„ë² ë” ì´ˆê¸°í™” (SSL ì˜¤ë¥˜ ì²˜ë¦¬)
        text_embedder.warm_up()
        print("âœ… ì±—ë´‡ RAG íŒŒì´í”„ë¼ì¸ ì¤€ë¹„ ì™„ë£Œ.")
        return text_embedder, retriever, prompt_builder
    except Exception as e:
        print(f"âŒ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None

def create_gemini_response(prompt):
    """Gemini APIë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ """
    try:
        genai.configure(api_key=os.environ.get("GOOGLE_API_KEY"))
        model = genai.GenerativeModel('gemini-2.0-flash')  # Updated to available model
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        error_msg = str(e)

        # 1) AI ë¬´ë£Œ ì‚¬ìš©ëŸ‰(Quota) ì´ˆê³¼ ë˜ëŠ” Rate Limit ì´ˆê³¼
        if "429" in error_msg or "Resource exhausted" in error_msg:
            raise HTTPException(
                status_code=429,
                detail="AI Quota Exceeded"
            )

        # 2) API Key ë¬¸ì œ
        if "API key" in error_msg or "permission" in error_msg.lower():
            raise HTTPException(
                status_code=403,
                detail="Permission Denied"
            )

        # 3) ê¸°íƒ€ ì˜¤ë¥˜
        raise HTTPException(
            status_code=500,
            detail="Gemini Internal Error"
        )
    
# --- 5. ë°±ì—”ë“œ í…ŒìŠ¤íŠ¸ìš© ì±—ë´‡ ì‹¤í–‰ ---
# def ask_chatbot(question, text_embedder, retriever, prompt_builder):
    """
    (âœ¨ ì‹ ê·œ ë¡œì§)
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„ì„œ FAQ(ê·œì¹™)ë¥¼ ë¨¼ì € í™•ì¸í•˜ê³ , 
    ì—†ìœ¼ë©´ RAG íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ "ë¼ìš°í„°"
    """
    print(f"\n[ì§ˆë¬¸] ğŸ’¬: {question}")
    
    # --- 1ë‹¨ê³„: ê·œì¹™ ê¸°ë°˜ FAQ í™•ì¸ (Req 1 & 2) ---
    # ê¸°íšì•ˆì˜ "í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€" ë¡œì§
    for idx, keywords in enumerate(FAQ_KEYWORDS):
        for kw in keywords:
            if kw in question:
                return FIXED_FAQ_DATABASE[idx]
            
    # 2-A) ë¨¼ì € ë™ì˜ì–´ ê¸°ë°˜ ëŒ€í‘œ í‚¤ì›Œë“œ ë§¤í•‘
    rep_keyword = find_representative_keyword(question)
    if rep_keyword:
        print(f"ğŸ” ë™ì˜ì–´ ë§¤í•‘: '{question}' â†’ ëŒ€í‘œ í‚¤ì›Œë“œ '{rep_keyword}'ë¡œ ê²€ìƒ‰")
        question = rep_keyword

    # --- 2ë‹¨ê³„: RAG + LLM ì‘ë‹µ (Req 3) ---
    print("(ê·œì¹™ ê¸°ë°˜ ë‹µë³€ ì—†ìŒ. RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰...)")
    try:
        # (A) ì§ˆë¬¸ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
        query_embedding_result = text_embedder.run(text=question)
        # retrieverê°€ ì½ì„ ìˆ˜ ìˆë„ë¡ ì„ë² ë”©ë§Œ êº¼ë‚´ëŠ” ì‘ì—…
        query_embedding = query_embedding_result["embedding"]
        
        # (B) ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        retrieved_docs = retriever.run(query_embedding=[query_embedding])["documents"]
        
        if not retrieved_docs:
            emp = find_best_employee(question)

            if emp:
                dept = emp["department"]
                name = emp["name"]
                pos = emp["position"]
                phone = emp["phone"]

                return {
                    "response": (
                        f"í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ì •í™•í•œ ì•ˆë‚´ê°€ ì–´ë µìŠµë‹ˆë‹¤.\n"
                        f"ìì„¸í•œ ë‚´ìš©ì€ {dept} {name} {pos}ë‹˜({phone})ê»˜ ë¬¸ì˜ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
                    )
                }

            return {
                "response": (
                    "í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•´ ê´€ë ¨ ë¬¸ì„œì™€ ë‹´ë‹¹ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                    "ê²½ì˜ì§€ì›ë¶€ë¡œ ë¬¸ì˜ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
                )
            }

        
        prompt_docs = []
        for d in retrieved_docs:
            prompt_docs.append(
                Document(id=d.id, content=d.content, meta=d.meta)
    )

        prompt_result = prompt_builder.run(documents=prompt_docs, question=question)

        full_prompt = prompt_result["prompt"]
        
        # (D) Gemini APIë¡œ ë‹µë³€ ìƒì„±
        answer = create_gemini_response(full_prompt)
        print(f"[ë‹µë³€] ğŸ¤– (AI ìƒì„±): {answer}")
        return answer
        
    except Exception as e:
        error_msg = f"ì±—ë´‡ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        print(f"[ì˜¤ë¥˜] âŒ: {error_msg}")
        return error_msg


# if __name__ == "__main__":
#     # ì±—ë´‡ íŒŒì´í”„ë¼ì¸ 1íšŒ ì´ˆê¸°í™”
#     pipeline_components = initialize_chatbot()
    
#     if pipeline_components:
#         text_embedder, retriever, prompt_builder = pipeline_components
        
#         # (í…ŒìŠ¤íŠ¸)
        
#         # (1) FAQ ì§ˆë¬¸ (RAG ë¯¸ì‚¬ìš©)
#         ask_chatbot("ì—°ì°¨ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?", text_embedder, retriever, prompt_builder)
        
#         # (2) ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ (RAG ì‚¬ìš©)
#         ask_chatbot("ì •ë³´ê³µê°œë¥¼ ì²­êµ¬ë°›ì€ ë¶€ì„œëŠ” ë©°ì¹  ë‚´ì— ì²˜ë¦¬ í•´ì•¼í•´?", text_embedder, retriever, prompt_builder)

# ì±—ë´‡ ë¶€íŒ… ë¡œì§
@app.on_event("startup")
def startup_event():
    global text_embedder, retriever, prompt_builder
    pipeline_components = initialize_chatbot()
    if pipeline_components:
        text_embedder, retriever, prompt_builder = pipeline_components


@app.post("/api/chat")
async def chat(request: Request):
    global text_embedder, retriever, prompt_builder
    data = await request.json()
    question = data.get("message", "")
    print(f"ğŸ’¬ ì‚¬ìš©ì ì§ˆë¬¸: {question}")

    # 1ï¸âƒ£ ê·œì¹™ ê¸°ë°˜ FAQ ë¨¼ì € í™•ì¸
    for idx, keywords in enumerate(FAQ_KEYWORDS):
        for kw in keywords:
            if kw in question:
                return {"response": FIXED_FAQ_DATABASE[idx]}


    # 2ï¸âƒ£ RAG + Gemini í˜¸ì¶œ
    
    rep_keyword = find_representative_keyword(question)
    if rep_keyword:
        print(f"ğŸ” ë™ì˜ì–´ ë§¤í•‘: '{question}' â†’ '{rep_keyword}'")
        question = rep_keyword

    # 3ï¸âƒ£ ì§ˆë¬¸ ì„ë² ë”© ìƒì„± 
    query_emb = text_embedder.run(text=question)["embedding"]
    # 4ï¸âƒ£ DuckDB ê²€ìƒ‰
    docs = retriever.run(query_embedding=[query_emb])["documents"]
    print(f"DuckDB ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: {len(docs)}")

    if not docs:
        # ê´€ë ¨ ë¬¸ì„œ ì—†ìœ¼ë©´ ë‹´ë‹¹ì ì¶”ì²œ
        print("ğŸ” ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ â†’ ë‹´ë‹¹ì ì¶”ì²œ ë¡œì§ ì‹¤í–‰")
        emp = find_best_employee(question)

        if emp:
            dept = emp["department"]
            name = emp["name"]
            pos = emp["position"]
            phone = emp["phone"]

            return {
                "response": (
                    f"í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ì •í™•í•œ ì•ˆë‚´ê°€ ì–´ë µìŠµë‹ˆë‹¤.\n"
                    f"ìì„¸í•œ ë‚´ìš©ì€ {dept} {name} {pos}ë‹˜({phone})ê»˜ ë¬¸ì˜ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
                )
            }

        return {
            "response": (
                "í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•´ ê´€ë ¨ ë¬¸ì„œì™€ ë‹´ë‹¹ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
            )
        }

    # 6ï¸âƒ£ ë¬¸ì„œ ìˆìŒ â†’ RAG + Gemini
    prompt = prompt_builder.run(documents=docs, question=question)["prompt"]
    answer = create_gemini_response(prompt)
    # ì¶œì²˜ ì •ë³´ ì¶”ê°€ 
    # --- ğŸ”¥ ì¶œì²˜ í¬ë§·íŒ… ---
    try:
        raw_name = docs[0].meta.get("file_name", "ì¶œì²˜ ì •ë³´ ì—†ìŒ")
        # .pdf ì œê±°
        if raw_name.lower().endswith(".pdf"):
            clean_name = raw_name[:-4]
        else:
            clean_name = raw_name

        answer += f"\n\nğŸ“„ ì¶œì²˜: {clean_name}"

    except Exception:
        answer += "\n\nğŸ“„ ì¶œì²˜: ì•Œ ìˆ˜ ì—†ìŒ"
    return {"response": answer}
    
    # except Exception as e:
    #     return {"response": f"ì„œë²„ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}
    
@app.post("/api/faq")
async def faq(request: Request):
    data = await request.json()
    faq_number = data.get("faq_number")

    # ìˆ«ìê°€ ìœ íš¨í•œì§€ ê²€ì‚¬
    if faq_number is None or not isinstance(faq_number, int):
        return {"response": "FAQ ë²ˆí˜¸ê°€ ì˜ëª» ì „ë‹¬ë˜ì—ˆìŠµë‹ˆë‹¤."}

    # ë¦¬ìŠ¤íŠ¸ ë²”ìœ„ ê²€ì‚¬
    if faq_number < 0 or faq_number >= len(FIXED_FAQ_DATABASE):
        return {"response": "í•´ë‹¹ FAQ í•­ëª©ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}

    # í•´ë‹¹ FAQ ë‹µë³€ì„ ë°˜í™˜
    return {"response": FIXED_FAQ_DATABASE[faq_number]}
