import os
import duckdb
import json
import numpy as np
from haystack.components.embedders import SentenceTransformersTextEmbedder
from haystack.components.builders import PromptBuilder
from haystack.dataclasses import Document
import google.generativeai as genai
from dotenv import load_dotenv

from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware


# --- 2. ê²½ë¡œ ë° ëª¨ë¸ ì„¤ì • ---
# EMBEDDING_MODEL = "all-MiniLM-L6-v2"  # build_index.pyì™€ ë™ì¼í•œ ëª¨ë¸ ì‚¬ìš©
EMBEDDING_MODEL = "jhgan/ko-sbert-nli"  # í•œêµ­ì–´ ëª¨ë¸ (SSL ë¬¸ì œ í•´ê²° í›„ ì‚¬ìš©)
DB_PATH = "hibot_store.db"  # build_index.pyì™€ ë™ì¼í•œ DuckDB íŒŒì¼ ê²½ë¡œ
# KEYWORD_FILE = "document_keywords.json" # ë¬¸ì„œ í‚¤ì›Œë“œ ë§¤í•‘ íŒŒì¼ ê²½ë¡œ
SYNONYM_MAP_PATH = "synonym_map.json" # ë™ì˜ì–´ íŒŒì¼ ê²½ë¡œ 
EMPLOYEE_JSON_PATH = "employee_roles.json" # ì§ì› ì—­í•  ì •ë³´ íŒŒì¼ ê²½ë¡œ

text_embedder = None
retriever = None
prompt_builder = None



# --- 0. [í•„ìˆ˜] API í‚¤ ì„¤ì • ---
# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

google_api_key = os.getenv("GOOGLE_API_KEY")
if google_api_key:
    os.environ["GOOGLE_API_KEY"] = google_api_key
else:
    print("âš ï¸  ê²½ê³ : GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    # (API í‚¤ê°€ ì—†ì–´ë„ FAQ ê¸°ëŠ¥ì€ ì‘ë™í•©ë‹ˆë‹¤)

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],      # ëª¨ë“  ë„ë©”ì¸ í—ˆìš©
    allow_credentials=True,  
    allow_methods=["*"],      # ëª¨ë“  HTTP ë©”ì„œë“œ í—ˆìš©
    allow_headers=["*"],      # ëª¨ë“  í—¤ë” í—ˆìš©
)

# --- 1. [ì‹ ê·œ] ê·œì¹™ ê¸°ë°˜ FAQ ë°ì´í„°ë² ì´ìŠ¤ (Req 1 & 2) ---
# ê¸°íšì•ˆì˜ "Quick Reply" ë° "FAQ ìë™ ì‘ë‹µ"ìš©
# í‚¤(Keyword)ê°€ ì§ˆë¬¸ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´, AI(RAG)ë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šê³  ì¦‰ì‹œ ì´ ë‹µë³€ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
# (í‚¤ì›Œë“œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì ì„ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤)
# --- 1. ìˆœì„œ ê¸°ë°˜ FAQ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€ê²½ ---
FIXED_FAQ_DATABASE = [
    # 1ï¸âƒ£ ì‹œê°„ì™¸ê·¼ë¬´
    """## ğŸ“Œ ì‹œê°„ì™¸ê·¼ë¬´ ì‹ ì²­ ë°©ë²• ë° ì‹ ì²­ ê°€ëŠ¥ ì‹œê°„

**ê²½ë¡œ:**  
`ì¸ì‚¬ê·¼íƒœ(í™•ì¥) â†’ ì‹œê°„ì™¸ê·¼ë¬´ â†’ ì‹œê°„ì™¸ê·¼ë¬´ ì‹ ì²­ê´€ë¦¬`

**ì‹ ì²­ ê°€ëŠ¥ ì‹œê°„**  
- **1ì¼ ìµœëŒ€:** 3ì‹œê°„ 30ë¶„  
- **ì›” ìµœëŒ€:** 15ì‹œê°„  
- **íœ´ê²Œì‹œê°„ 30ë¶„ ì œì™¸ í›„ ì‹ ì²­ (ì¡°ê¸°ê·¼ë¬´Â·ì—°ì¥ê·¼ë¬´ ë™ì¼ ì ìš©)**  
- **ì¡°ê¸° + ì—°ì¥ ëª¨ë‘ í•˜ëŠ” ê²½ìš°:** ê°ê° 30ë¶„ì”© íœ´ê²Œì‹œê°„ ì œì™¸  
- **ì¡°ê¸°/ì—°ì¥ ê·¼ë¬´ ì‹œ:** *ìˆ˜ë‹¹* ë˜ëŠ” *ë³´ìƒíœ´ê°€* ì¤‘ **1ê°€ì§€ë§Œ ì‹ ì²­ ê°€ëŠ¥**

**ê´€ë ¨ê·¼ê±°**  
- ì—°ì¥ê·¼ë¡œ ë° íŠ¹ê·¼ë§¤ì‹ë¹„ ì§€ê¸‰ê¸°ì¤€


## ğŸ“Œ íœ´ì¼ê·¼ë¬´ ë° ì‹œê°„ì™¸ê·¼ë¬´ ì‹ ì²­ ì·¨ì†Œ ë°©ë²•

1) **ê²°ì¬ì ê²°ì¬ ì·¨ì†Œ**  

2) **ê·¸ë£¹ì›¨ì–´ ê²½ë¡œ:**  
`ì¸ì‚¬ê·¼íƒœ(í™•ì¥) â†’ ì‹œê°„ì™¸ê·¼ë¬´ â†’ ì‹œê°„ì™¸ê·¼ë¬´ ìŠ¹ì¸`

**ì·¨ì†Œ ë°©ë²•:**  
- ì·¨ì†Œí•  ì‹ ì²­ ê±´ **ë”ë¸” í´ë¦­**  
- **[ì‹ ì²­ì·¨ì†Œ]** ë²„íŠ¼ ì„ íƒ


## ğŸ“Œ ì‹œê°„ì™¸ê·¼ë¬´ ì‹œ ë³´ìƒíœ´ê°€ ë° ìˆ˜ë‹¹ ë™ì‹œ ì‹ ì²­ ì—¬ë¶€

- **ë™ì‹œ ì‹ ì²­ ë¶ˆê°€**  
- ê·¼ë¬´ìœ í˜•(ì¡°ê¸°/ì—°ì¥)ë³„ë¡œ **ìˆ˜ë‹¹ ë˜ëŠ” ë³´ìƒíœ´ê°€ ì¤‘ 1ê°œë§Œ ì„ íƒ ê°€ëŠ¥**

**ì˜ˆì‹œ (ë¶ˆê°€ ì‚¬ë¡€)**  
- 24.02.06. ì—°ì¥ê·¼ë¬´ â€“ ìˆ˜ë‹¹ 30ë¶„  
- 24.02.06. ì—°ì¥ê·¼ë¬´ â€“ ë³´ìƒíœ´ê°€ 1ì‹œê°„  â†’ **ë™ì‹œ ì‹ ì²­ ë¶ˆê°€**
""",

    # 2ï¸âƒ£ ê°€ì¡±ìˆ˜ë‹¹
    """## ğŸ“Œ ê°€ì¡±ìˆ˜ë‹¹ ì‹ ì²­ ë°©ë²•

### âœ” ì§€ê¸‰ ìš”ê±´ ë° ê¸°ì¤€
- ã€Œë³´ìˆ˜ê·œì • ì‹œí–‰ê·œì¹™ã€ ë³„í‘œ ì œ1í˜¸ ì°¸ì¡°

### âœ” ì§€ê¸‰ ì‹ ì²­ ë°©ë²•
- ê¸‰ì—¬ ë‹´ë‹¹ì ì´ë©”ì¼ë¡œ ì‹ ì²­
- **ì²¨ë¶€ì„œë¥˜**
  1) ê°€ì¡±ìˆ˜ë‹¹ ì§€ê¸‰ ì‹ ì²­ì„œ(ì„œëª… í•„ìˆ˜)  
     *ì„œì‹: ã€Œë³´ìˆ˜ê·œì • ì‹œí–‰ê·œì¹™ã€ ë³„ì§€ ì œ1í˜¸*  
  2) ì¦ë¹™ì„œë¥˜(ì§ì›ì˜ í”¼ë¶€ì–‘ìì„ì„ í™•ì¸í•  ìˆ˜ ìˆëŠ” ì„œë¥˜)
     - í”¼ë¶€ì–‘ìì™€ì˜ ê°€ì¡±ê´€ê³„, ì„±ëª…, ìƒë…„ì›”ì¼ ëª¨ë‘ í¬í•¨ í•„ìˆ˜
     - **ì§ê³„ì¡´ì†:** ì£¼ë¯¼ë“±ë¡ë“±ë³¸ ë˜ëŠ” ê±´ê°•ë³´í—˜ ìê²©í™•ì¸ì„œ  
     - **ì§ê³„ì¡´ì† ì™¸:** ê°€ì¡±ê´€ê³„ì¦ëª…ì„œ, ì£¼ë¯¼ë“±ë¡ë“±ë³¸, ê±´ê°•ë³´í—˜ ìê²©í™•ì¸ì„œ ì¤‘ íƒ1  
     - **ì¥ì•  ìš”ê±´ í•´ë‹¹ ì‹œ:** ì¥ì• ì¸ì¦ëª…ì„œ

### âœ” ì§€ê¸‰ ë°©ë²•
- **ì‹¤ì œ ì´ë©”ì¼ ì ‘ìˆ˜ì¼ ê¸°ì¤€**ìœ¼ë¡œ ê¸‰ì—¬ì¼ì— ì •ì•¡ ì§€ê¸‰  
  *(ì‹ ì²­ì„œì— ì ì€ ë‚ ì§œê°€ ì•„ë‹ˆë¼ ì‹¤ì œ ì´ë©”ì¼ ì ‘ìˆ˜ì¼)*

---

## ğŸ“Œ 2. ìƒì‹¤ ì‹ ê³  ë°©ë²•

- ìƒì‹¤ ìš”ê±´ ë°œìƒ ì‹œ **ì¦‰ì‹œ ì‹ ê³  í•„ìˆ˜** (ì‹ ê³  ë°©ë²• ë™ì¼: ì´ë©”ì¼ ì œì¶œ)
- **ì œì¶œ ì„œë¥˜**
  1) ê°€ì¡±ìˆ˜ë‹¹ ìƒì‹¤ ì‹ ê³ ì„œ(ì„œëª… í•„ìˆ˜)  
  2) ì¦ë¹™ì„œë¥˜(ìƒì‹¤ ì‚¬ìœ  ë°œìƒì¼ í™•ì¸ ê°€ëŠ¥ ì„œë¥˜)

**ì˜ˆì‹œë³„ ì œì¶œ ì„œë¥˜**  
- ë¶€ëª¨ë‹˜ì˜ ì „ì¶œ â†’ í”¼ë¶€ì–‘ì ê¸°ì¤€ ì£¼ë¯¼ë“±ë¡ë“±ë³¸(ì „ì¶œì¼ í™•ì¸)  
- ê±´ê°•ë³´í—˜ í”¼ë¶€ì–‘ì ìê²© ìƒì‹¤ â†’ í”¼ë¶€ì–‘ì ê¸°ì¤€ ê±´ê°•ë³´í—˜ ìê²©â€˜ë“ì‹¤â€™í™•ì¸ì„œ  
- í”¼ë¶€ì–‘ì ì‚¬ë§ â†’ ì‚¬ë§ì§„ë‹¨ì„œ ë“±  
- ì´í˜¼ìœ¼ë¡œ ì¸í•œ ìƒì‹¤ â†’ í˜¼ì¸ê´€ê³„ì¦ëª…ì„œ(ì´í˜¼ì¼ í™•ì¸)  
- ìë…€ ë‚˜ì´ ìš”ê±´ ì´ˆê³¼(ë§Œ 19ì„¸ ì´ìƒ) â†’ ê°€ì¡±ê´€ê³„ì¦ëª…ì„œ(ìƒë…„ì›”ì¼ í™•ì¸)

---

## ğŸ“Œ 3. ìœ ì˜ì‚¬í•­

- ê°€ì¡±ìˆ˜ë‹¹ ì •ê¸°ì¡°ì‚¬ì—ì„œ **ë¶€ì •ìˆ˜ê¸‰ ë°œìƒ ì‹œ í™˜ìˆ˜ ì¡°ì¹˜**
- ë¶€ì–‘ê°€ì¡±ì´ **ê³µë¬´ì›ì¸ ê²½ìš° ê°€ì¡±ìˆ˜ë‹¹ ì¤‘ë³µ ì§€ê¸‰ ë¶ˆê°€**
""",

    # 3ï¸âƒ£ ë³µì§€í¬ì¸íŠ¸
    """## ğŸ“Œ 1. ë³µì§€í¬ì¸íŠ¸ëŠ” ì–¼ë§ˆë‚˜ ë¶€ì—¬ë˜ë‚˜ìš”?

### âœ” ë³µì§€í¬ì¸íŠ¸ ë°°ì • ê¸°ì¤€
- **ì ìš©ëŒ€ìƒ:** ì¬ì§ ì¤‘ì¸ ì •ê·œì§Â·ê³„ì•½ì§ ì§ì› ë° ì±„ìš© ì˜ˆì •ì
- **ë°°ì •ê¸ˆì•¡:** 1ì¸ë‹¹ ì—°ê°„ 1,000,000í¬ì¸íŠ¸(1P=1ì›)
  - ë‹¨ì²´ë³´í—˜ë£Œ ì„ ê³µì œ í›„ **ì”ì•¡ í•œë„ ë‚´ ì²­êµ¬ ê°€ëŠ¥**
- **ì‹ ë¶„ë³€ë™ì ì ìš© ì›ì¹™**
  - ì‹ ê·œì±„ìš©/íœ´ì§ ë“± ì‹ ë¶„ ë³€ë™ ì‹œ **ì›”í•  ê³„ì‚°(83,000P/ì›”)**
  - ë³€ë™ì¼ì´ ì†í•œ ë‹¬ì— **15ì¼ ì´ìƒ ê·¼ë¬´ ì‹œ í•´ë‹¹ ì›” í¬ì¸íŠ¸ ì§€ê¸‰**
  - ì—°ì¤‘ í‡´ì‚¬ ì‹œ ì¬ì§ê¸°ê°„ ê¸°ì¤€ ì›”í•  ì •ì‚°, **ì´ˆê³¼ ì‚¬ìš©ë¶„ í™˜ìˆ˜**
  - ì—°ì¤‘ ì…ì‚¬ìëŠ” **ì…ì‚¬ì¼ ì´í›„ ì‚¬ìš©ë‚´ì—­ë§Œ ì¸ì •**

---

## ğŸ“Œ  ë³µì§€í¬ì¸íŠ¸ëŠ” ì–´ë–»ê²Œ ì²­êµ¬í•˜ë‚˜ìš”?

### âœ” ì²­êµ¬ ì ˆì°¨ ë° ì¼ì •
- ì—°ê°„ **2íšŒ(ìƒÂ·í•˜ë°˜ê¸°)** ì²­êµ¬  
- ì—°ì¤‘ í‡´ì‚¬ ì‹œ: í‡´ì‚¬ ì „ **ê²°ê³¼ë³´ê³  + ì§€ì¶œê²°ì˜ì„œ ì œì¶œ ì™„ë£Œ ê±´ë§Œ ì§€ê¸‰**

- ë¶€ì„œë¡œ ë°œì†¡ë˜ëŠ” ì •ì‚° ì•ˆë‚´ ê³µë¬¸ ì´í›„,  
  **ê° ë¶€ì„œ ë‹´ë‹¹ìì—ê²Œ ì²­êµ¬ ì–‘ì‹ ì œì¶œ â†’ ì•„ë˜ ì ˆì°¨ì— ë”°ë¼ ì§€ê¸‰**

### âœ” ì œì¶œ ì–‘ì‹
1. ë³µì§€í¬ì¸íŠ¸ ì‚¬ìš© ì²­êµ¬ì„œ  
2. ë³µì§€í¬ì¸íŠ¸ ì‚¬ìš© ì¦ë¹™ë‚´ì—­  
3. ì‚¬ìš©ì¹´ë“œ ì‚¬ë³¸  
4. ë³µì§€í¬ì¸íŠ¸ ì‚¬ìš© ê´€ë¦¬ëŒ€ì¥  

â€» ì‚¬ìš©ì¼ìÂ·ê²°ì œí’ˆëª©ì´ í™•ì¸ ê°€ëŠ¥í•œ **ì ê²©ì¦ë¹™(ì˜ìˆ˜ì¦, ì¹´ë“œë§¤ì¶œì „í‘œ, ê³„ì‚°ì„œ)** í•„ìˆ˜ ì²¨ë¶€

---

## ğŸ“Œ ìƒÂ·í•˜ë°˜ê¸° ìƒì„¸ ì¼ì •

| ìƒë°˜ê¸° | í•˜ë°˜ê¸° | í–‰ìœ„ì | ë‚´ìš© |
|-------|-------|--------|------|
| 5.23  | 11.28 | ì „ ì§ì› | ê° ë¶€ì„œ ë‹´ë‹¹ìì—ê²Œ ì‚¬ìš©ë‚´ì—­ ì œì¶œ |
| 5.30  | 12.5  | ê° ë¶€ì„œ ë‹´ë‹¹ì(ì„œë¬´) | ì í•©ì„± ê²€í† (1ì°¨) ë° ê²°ê³¼ë³´ê³  ìƒì‹  |
| 6.9   | 12.12 | ì¸ì¬ê°œë°œíŒ€ ë³µë¦¬í›„ìƒ ë‹´ë‹¹ | ì í•©ì„± ê²€í† (2ì°¨) |
| 6.13  | 12.19 | ê° ë¶€ì„œ ë‹´ë‹¹ì ë° ë¶€ì„œì¥ | ì§€ì¶œê²°ì˜ì„œ ìƒì‹  ë° ìŠ¹ì¸ í›„ ìš´ì˜ì§€ì›íŒ€ ì œì¶œ |
| 6.25  | 12.24 | ìš´ì˜ì§€ì›íŒ€ ì§€ì¶œ ë‹´ë‹¹ | ì˜ˆì‚°ê³¼ëª© ê²€í†  ë° ê°œì¸ë³„ ì§€ê¸‰ |
""",

    # 4ï¸âƒ£ ì¶œì¥ì‹ ì²­
    """##  ì¶œì¥ì‹ ì²­ ë° ì—¬ë¹„ì •ì‚° ë°©ë²•

- **ì¶œì¥ì‹ ì²­ ê²½ë¡œ:**  
  `ì¸ì‚¬ê·¼íƒœ(í™•ì¥) â†’ ê·¼íƒœ ì‹ ì²­ì„œ â†’ ì¶œì¥ì‹ ì²­`

- **ì •ì‚° ê¸°ì¤€:**  
  - êµ­ë‚´ì¶œì¥: **1ì£¼ì¼ ì´ë‚´**  
  - êµ­ì™¸ì¶œì¥: **2ì£¼ì¼ ì´ë‚´**  
  - ìš´ì„Â·ìˆ™ë°•ë¹„ì˜ **ì„¸ë¶€ ì‚¬ìš© ë‚´ì—­ì´ í™•ì¸ ê°€ëŠ¥í•œ ì¦ë¹™ì„œë¥˜**ë¥¼ ê°–ì¶”ì–´ ì •ì‚° ì‹ ì²­

---

## 2. ì¶œì¥ ì¶œë°œì§€Â·ë³µê·€ì§€ì  ê¸°ì¤€

- **ì›ì¹™:** ê·¼ë¬´ì§€(ìƒê³µíšŒì˜ì†Œ, ì—°ì„¸ë´‰ë˜ë¹Œë”©)ë¥¼ ì¶œë°œÂ·ë³µê·€ ì§€ì ìœ¼ë¡œ í•¨  
- ë‹¨, í˜•í¸ì— ë”°ë¼ **ê·¼ë¬´ì§€ ì™¸ ì¥ì†Œ**ì—ì„œ ì¶œë°œÂ·ë³µê·€ ê°€ëŠ¥  
  - ì´ ê²½ìš° ì•„ë˜ ê¸°ì¤€ì— ë”°ë¼ **êµí†µë¹„ ì§€ê¸‰ ë°©ì‹** ì ìš©

| êµ¬ë¶„ | êµí†µë¹„ ì§€ê¸‰ ê¸°ì¤€ |
|------|---------------------|
| ê·¼ë¬´ì§€ ì™•ë³µ êµí†µë¹„ > ê·¼ë¬´ì§€ ì™¸ ì¥ì†Œ ì™•ë³µ êµí†µë¹„ | **ì‹¤ë¹„ ì§€ê¸‰** |
| ê·¼ë¬´ì§€ ì™•ë³µ êµí†µë¹„ < ê·¼ë¬´ì§€ ì™¸ ì¥ì†Œ ì™•ë³µ êµí†µë¹„ | **ì‹¤ë¹„ ì§€ê¸‰(ë‹¨, ê·¼ë¬´ì§€ ì™•ë³µ êµí†µë¹„ í•œë„)** |

---

## 3. ê·¼ë¬´ì§€ ë‚´ ì¶œì¥ë¹„ ê³„ì‚° ë°©ë²•

| êµ¬ë¶„ | ì¶œì¥ ì‹œê°„ 4ì‹œê°„ ì´ìƒ | ì¶œì¥ ì‹œê°„ 4ì‹œê°„ ë¯¸ë§Œ |
|------|------------------------|------------------------|
| ê±°ë¦¬ ì™•ë³µ 2km ì´ìƒ | 20,000ì› | 10,000ì› |
| ê±°ë¦¬ ì™•ë³µ 2km ë¯¸ë§Œ | ì‹¤ë¹„(ìƒí•œ 20,000ì›) | ì‹¤ë¹„(ìƒí•œ 10,000ì›) |
""",

    # 5ï¸âƒ£ ì „ì‚°ì¥ë¹„/ì‹œì„¤ë¬¼ ê³ ì¥
    """##  ì „ì‚°ì¥ë¹„ ë° ì‹œì„¤ë¬¼ ê³ ì¥ ì‹œ ë¬¸ì˜ ë°©ë²•

### âœ” ì‚¬ë¬´ê¸°ê¸° ê³ ì¥Â·ìˆ˜ë¦¬ (ì •ë³´í™”ë¬¼í’ˆ ë‹´ë‹¹)
- PC ë° ì „ì‚°ìš©í’ˆ(ë³µí•©ê¸°, ì„¸ë‹¨ê¸° ë“±)ì˜ ê²½ìš°  
  ê¸°ê¸° **ì¤‘ê°„ ë˜ëŠ” í•˜ë‹¨ì— í‘œì‹œëœ ìˆ˜ë¦¬ ê¸°ì‚¬ ì—°ë½ì²˜**ë¡œ ì§ì ‘ ìœ ì„  ì—°ë½í•˜ì—¬ ê³ ì¥Â·ìˆ˜ë¦¬ ìš”ì²­

### âœ” ê¸°íƒ€ ì‹œì„¤ë¬¼ ê³ ì¥ (ì‹œì„¤ ë° ë¬¼í’ˆ ë‹´ë‹¹)
- ê²½ì˜ì§€ì›ë¶€ **ë¬¼í’ˆê´€ë¦¬ ë‹´ë‹¹ì**ì—ê²Œ ì—°ë½
"""
]


FAQ_KEYWORDS = [
    ["ì‹œê°„ì™¸ê·¼ë¬´", "ì‹œê°„ ì™¸ ê·¼ë¬´", "ì—°ì¥ê·¼ë¬´"],
    ["ê°€ì¡±ìˆ˜ë‹¹", "ê°€ì¡± ìˆ˜ë‹¹"],
    ["ë³µì§€í¬ì¸íŠ¸", "ë³µì§€ í¬ì¸íŠ¸"],
    ["ì¶œì¥ì‹ ì²­", "ì—¬ë¹„ì •ì‚°"],
    ["ì „ì‚°ì¥ë¹„", "PC", "í”„ë¦°í„°", "ì‹œì„¤ë¬¼", "ê³ ì¥"],
    ["ë‚˜ì˜ê±´ê°•ê¸°ë¡ì•± í™ë³´ë¶€ìŠ¤ê°€ ë­ì•¼?", "ë‚˜ì˜ê±´ê°•ê¸°ë¡ ì•± í™ë³´ë¶€ìŠ¤ ìš´ì˜ ê´€ë¦¬"],
]

# employee_roles.json ë¡œë”© í•¨ìˆ˜
def load_employee_roles():
    try:
        with open(EMPLOYEE_JSON_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"âš ï¸ employee_roles.json ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return []

EMPLOYEES = load_employee_roles()

def find_best_employee(question: str):
    """
    ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ê´€ë ¨ ìˆëŠ” ì§ì› ì¶”ì²œ
    ë§¤ì¹­ ì ìˆ˜ ê¸°ì¤€:
    - ì§ˆë¬¸ í‚¤ì›Œë“œê°€ ì—…ë¬´(task)ì— ë“±ì¥í•˜ë©´ +1
    """
    if not EMPLOYEES:
        return None

    # ì§ˆë¬¸ì„ ë‹¨ì–´ë¡œ ë¶„ë¦¬
    keywords = [w for w in question.split() if len(w) >= 2]

    best_match = None
    best_score = 0

    for emp in EMPLOYEES:
        score = 0
        for task in emp["tasks"]:
            for kw in keywords:
                if kw in task:
                    score += 1

        if score > best_score:
            best_score = score
            best_match = emp

    return best_match


# ë™ì˜ì–´ ë§µ ë¡œë“œ í•¨ìˆ˜
def load_synonym_map():
    try:
        with open(SYNONYM_MAP_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"âš ï¸ synonym_map.json ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return {}

SYNONYM_MAP = load_synonym_map()

# ê¸´ ë¬¸ì„œë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ëŠ” í•¨ìˆ˜
# def smart_trim(text, max_length=600):
#     if not text:
#         return ""

#     if len(text) <= max_length:
#         return text

#     trimmed = text[:max_length]

#     # ì—¬ëŸ¬ í›„ë³´ ë¬¸ì¥ë¶€í˜¸ ê²€ìƒ‰
#     end_marks = ['ë‹¤.', 'ìš”.', 'í•¨.', '.', '!', '?', '\n']

#     last_cut = -1
#     for mark in end_marks:
#         pos = trimmed.rfind(mark)
#         if pos != -1:
#             end_pos = pos + len(mark)
#             if end_pos > last_cut:
#                 last_cut = end_pos

#     # ë¬¸ì¥ë¶€í˜¸ ì°¾ì€ ê²½ìš°
#     if last_cut != -1:
#         return trimmed[:last_cut]

#     # ë¬¸ì¥ë¶€í˜¸ ì—†ìœ¼ë©´ ë‹¨ì–´ ê¸°ì¤€ìœ¼ë¡œ ìë¦„
#     last_space = trimmed.rfind(" ")
#     if last_space != -1:
#         return trimmed[:last_space]

#     return trimmed



# --- 3. ì§ˆë¬¸ê³¼ ë¹„ìŠ·í•œ ë¬¸ì„œë¥¼ DuckDBì—ì„œ ì°¾ì•„ì£¼ëŠ” ê²€ìƒ‰ ì—”ì§„ ---
class DuckDBEmbeddingRetriever:
    """
    DuckDB ê¸°ë°˜ semantic search retriever
    âœ” top_k ê°œìˆ˜ ì œí•œ
    âœ” similarity threshold ì ìš©
    âœ” similarity ì •ë³´ metaì— ì €ì¥
    âœ” ì˜ˆì˜ê²Œ ë¡œê·¸ ì¶œë ¥
    """

    def __init__(self, db_path, top_k=6, threshold=0.5):
        self.db_path = db_path
        self.top_k = top_k
        self.threshold = threshold
        self.conn = None
        
    def connect(self):
        if self.conn is None:
            self.conn = duckdb.connect(self.db_path)


    def run(self, query_embedding):
        """query_embedding(list) â†’ DuckDBì—ì„œ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        self.connect()

        # ëª¨ë“  ë¬¸ì„œ ë¡œë“œ
        docs_data = self.conn.execute("""
            SELECT id, content, meta, embedding 
            FROM documents 
            WHERE embedding IS NOT NULL
        """).fetchall()

        if not docs_data:
            return {"documents": []}

        query_emb = np.array(query_embedding[0])
        similarities = []

        print("\nğŸ“˜ [DuckDB Retriever] ë¬¸ì„œ ìœ ì‚¬ë„ ê³„ì‚° ì‹œì‘")
        print(f" - Threshold = {self.threshold}")
        print(" - --------------------------------------------")

        # ê° ë¬¸ì„œì™€ similarity ê³„ì‚°
        for doc_id, content, meta_str, embedding in docs_data:
            if not embedding:
                continue

            doc_emb = np.array(embedding)

            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarity = float(
                np.dot(query_emb, doc_emb) 
                / (np.linalg.norm(query_emb) * np.linalg.norm(doc_emb))
            )

            # ë©”íƒ€ ë¡œë“œ
            try:
                meta = json.loads(meta_str) if meta_str else {}
            except:
                meta = {}

            file_name = meta.get("file_name", "ì•Œ ìˆ˜ ì—†ìŒ")
            page = meta.get("page_number", "N/A")

            # ì˜ˆìœ ë¡œê·¸ ì¶œë ¥
            print(f"ğŸ” ë¬¸ì„œ: {file_name} (p.{page}) â†’ ìœ ì‚¬ë„: {similarity:.4f}")

            # threshold ë¯¸ë‹¬ â†’ ê±´ë„ˆë›°ê¸°
            if similarity < self.threshold:
                continue

            similarities.append((similarity, doc_id, content, meta))

        print(" - --------------------------------------------")

        # threshold ë¯¸ë‹¬ ë¬¸ì„œë§Œ ìˆì—ˆë‹¤ë©´
        if not similarities:
            print("âŒ threshold ì´ìƒ ë¬¸ì„œ ì—†ìŒ â†’ ë¬¸ì„œ ì—†ìŒìœ¼ë¡œ ì²˜ë¦¬ë¨")
            return {"documents": []}

        # ìƒìœ„ top_kë§Œ ì„ íƒ
        similarities.sort(reverse=True, key=lambda x: x[0])
        top_docs = similarities[:self.top_k]

        # Document ê°ì²´ ìƒì„±
        documents = []
        print("\nğŸ“˜ ìµœì¢… ì„ íƒëœ ë¬¸ì„œ(top_k)")
        for similarity, doc_id, content, meta in top_docs:
            meta["similarity"] = similarity
            print(f"âœ” {meta.get('file_name', 'ì•Œ ìˆ˜ ì—†ìŒ')} â†’ {similarity:.4f}")
            documents.append(Document(id=doc_id, content=content, meta=meta))

        print("------------------------------------------------\n")

        return {"documents": documents}

    

def find_representative_keyword(question: str):
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— SYNONYM_MAPì˜ ë™ì˜ì–´ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ 
    ëŒ€í‘œ í‚¤ì›Œë“œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    ì˜ˆ: 'ì•¼ê·¼ ì‹ ì²­ ì–´ë–»ê²Œ?' â†’ 'ì‹œê°„ì™¸ê·¼ë¬´'
    """
    for rep_keyword, synonyms in SYNONYM_MAP.items():
        # ëŒ€í‘œ ë‹¨ì–´ ìì²´ê°€ ì§ˆë¬¸ì— ìˆëŠ” ê²½ìš°
        if rep_keyword in question:
            return rep_keyword
        
        # ë™ì˜ì–´ë“¤ì´ ì§ˆë¬¸ ì•ˆì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€
        for syn in synonyms:
            if syn in question:
                return rep_keyword

    return None



# --- 4. [ì‹ ê·œ] RAG íŒŒì´í”„ë¼ì¸ "ë¼ìš°í„°" (Req 3) ---

def initialize_chatbot():
    print("ì±—ë´‡ ì´ˆê¸°í™” ì¤‘...")
    
    # (A) DuckDB ì—°ê²° í™•ì¸
    try:
        if not os.path.exists(DB_PATH):
            print(f"âŒ '{DB_PATH}' ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ë¨¼ì € 'python build_index.py' ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ë¬¸ì„œë¥¼ ìƒ‰ì¸í•´ì£¼ì„¸ìš”.")
            return None
        
        conn = duckdb.connect(DB_PATH)
        doc_count = conn.execute("SELECT COUNT(*) FROM documents").fetchone()[0]
        conn.close()
        print(f"âœ… '{DB_PATH}'ì—ì„œ {doc_count}ê°œ ë¬¸ì„œë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ '{DB_PATH}' ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        print("ë¨¼ì € 'python build_index.py' ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ë¬¸ì„œë¥¼ ìƒ‰ì¸í•´ì£¼ì„¸ìš”.")
        return None

    # (B) RAG íŒŒì´í”„ë¼ì¸ ì¤€ë¹„ (SSL ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨)
    try:
        # í•œêµ­ì–´ ë¬¸ì¥ì„ ìˆ«ì ë²¡í„°ë¡œ ìë™ ë³€í™˜í•´ì£¼ëŠ” ëª¨ë¸ì„ ë¡œë”© 
        text_embedder = SentenceTransformersTextEmbedder(model=EMBEDDING_MODEL)
        # ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰ê¸°(semantic search engine)
        # DuckDB íŒŒì¼(hibot_store.db)ì— ì ‘ì†í•´ì„œ ë¬¸ì„œë“¤ì˜ ì„ë² ë”©(vector) ëª©ë¡ì„ ì½ê³  
        # ì§ˆë¬¸ì˜  ì„ë² ë”©ê³¼ ì½”ì‚¬ì¸ ìœ ì‚¬ë„(similarity score)ë¥¼ ê³„ì‚°í•´ì„œ ê°€ì¥ ë¹„ìŠ·í•œ ë¬¸ì„œ **12(top_k=12)**ë¥¼ ë°˜í™˜í•¨
        retriever = DuckDBEmbeddingRetriever(db_path=DB_PATH, top_k=6)
        print("âœ… ì„ë² ë”ì™€ ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ì„ë² ë” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("ğŸ“‹ í•´ê²°ë°©ë²•:")
        print("   1. pip install --upgrade certifi")
        print("   2. ì¸í„°ë„· ì—°ê²° í™•ì¸")
        return None
    
    prompt_template = """
ë‹¹ì‹ ì€ ë‚´ë¶€ ê·œì •Â·ì§€ì¹¨Â·ì—…ë¬´ ë§¤ë‰´ì–¼ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì•„ë˜ [ì°¸ê³  ë¬¸ì„œ]ëŠ” ì§ˆë¬¸ê³¼ ê°€ì¥ ì—°ê´€ì„±ì´ ë†’ì€ ë¬¸ì„œë“¤ì…ë‹ˆë‹¤. ì§ˆë¬¸ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ë¬¸ì„œë¥¼ [ì°¸ê³  ë¬¸ì„œ]ë¥¼ ì •ë¦¬ í•´ì„œ ë‹µë³€í•´ ì£¼ì„¸ìš”.

[ì°¸ê³  ë¬¸ì„œ]
{% for doc in documents %}
ë¬¸ì„œ {{ loop.index }}:
- íŒŒì¼ëª…: {{ doc.meta.file_name }}
- ìœ ì‚¬ë„: {{ doc.meta.similarity }}
- ë‚´ìš©:
{{ doc.content }}
{% endfor %}

[ì§ˆë¬¸]: {{ question }}

[ë‹µë³€]:
"""
    prompt_builder = PromptBuilder(template=prompt_template, required_variables=["documents", "question"])
    
    # (C) ì„ë² ë” ì´ˆê¸°í™” (SSL ì˜¤ë¥˜ ì²˜ë¦¬)
    try:
        # ì„ë² ë” ì´ˆê¸°í™” (SSL ì˜¤ë¥˜ ì²˜ë¦¬)
        text_embedder.warm_up()
        print("âœ… ì±—ë´‡ RAG íŒŒì´í”„ë¼ì¸ ì¤€ë¹„ ì™„ë£Œ.")
        return text_embedder, retriever, prompt_builder
    except Exception as e:
        print(f"âŒ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None

def create_gemini_response(prompt):
    """Gemini APIë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ """
    try:
        genai.configure(api_key=os.environ.get("GOOGLE_API_KEY"))
        model = genai.GenerativeModel('gemini-2.0-flash')  # Updated to available model
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        error_msg = str(e)

        # 1) AI ë¬´ë£Œ ì‚¬ìš©ëŸ‰(Quota) ì´ˆê³¼ ë˜ëŠ” Rate Limit ì´ˆê³¼
        if "429" in error_msg or "Resource exhausted" in error_msg:
            raise HTTPException(
                status_code=429,
                detail=(
                    "### âš ï¸ ì‚¬ìš©ëŸ‰ ì´ˆê³¼ ì•ˆë‚´\n"
                    "í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ AI ìš”ì²­ëŸ‰ì´ ëª¨ë‘ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
                    "**ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.**\n"
                    "ìš”ì²­ëŸ‰ì´ ìë™ìœ¼ë¡œ ë³µêµ¬ë  ë•Œê¹Œì§€ ëŒ€ê¸°í•´ì•¼ í•©ë‹ˆë‹¤."
                )
            )


        # 2) API Key ë¬¸ì œ
        if "API key" in error_msg or "permission" in error_msg.lower():
            raise HTTPException(
                status_code=403,
                detail=(
                    "### ğŸ”‘ ì¸ì¦ ì˜¤ë¥˜\n"
                    "AI ì„œë¹„ìŠ¤ ì¸ì¦ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n"
                    "ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì—¬ **API Key ì„¤ì •ì„ í™•ì¸**í•´ì£¼ì„¸ìš”."
                )

            )

        # 3) ê¸°íƒ€ ì˜¤ë¥˜
        raise HTTPException(
            status_code=500,
            detail=(
                "### ğŸš¨ ì‹œìŠ¤í…œ ì˜¤ë¥˜\n"
                "AI ì‘ë‹µ ìƒì„± ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n"
                "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n"
                "ë¬¸ì œê°€ ê³„ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
            )
        )
    
# --- 5. ë°±ì—”ë“œ í…ŒìŠ¤íŠ¸ìš© ì±—ë´‡ ì‹¤í–‰ ---
# def ask_chatbot(question, text_embedder, retriever, prompt_builder):
    """
    (âœ¨ ì‹ ê·œ ë¡œì§)
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„ì„œ FAQ(ê·œì¹™)ë¥¼ ë¨¼ì € í™•ì¸í•˜ê³ , 
    ì—†ìœ¼ë©´ RAG íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ "ë¼ìš°í„°"
    """
    print(f"\n[ì§ˆë¬¸] ğŸ’¬: {question}")
    
    # --- 1ë‹¨ê³„: ê·œì¹™ ê¸°ë°˜ FAQ í™•ì¸ (Req 1 & 2) ---
    # ê¸°íšì•ˆì˜ "í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€" ë¡œì§
    for idx, keywords in enumerate(FAQ_KEYWORDS):
        for kw in keywords:
            if kw in question:
                return FIXED_FAQ_DATABASE[idx]
            
    # 2-A) ë¨¼ì € ë™ì˜ì–´ ê¸°ë°˜ ëŒ€í‘œ í‚¤ì›Œë“œ ë§¤í•‘
    rep_keyword = find_representative_keyword(question)
    if rep_keyword:
        print(f"ğŸ” ë™ì˜ì–´ ë§¤í•‘: '{question}' â†’ ëŒ€í‘œ í‚¤ì›Œë“œ '{rep_keyword}'ë¡œ ê²€ìƒ‰")
        question = rep_keyword

    # --- 2ë‹¨ê³„: RAG + LLM ì‘ë‹µ (Req 3) ---
    print("(ê·œì¹™ ê¸°ë°˜ ë‹µë³€ ì—†ìŒ. RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰...)")
    try:
        # (A) ì§ˆë¬¸ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
        query_embedding_result = text_embedder.run(text=question)
        # retrieverê°€ ì½ì„ ìˆ˜ ìˆë„ë¡ ì„ë² ë”©ë§Œ êº¼ë‚´ëŠ” ì‘ì—…
        query_embedding = query_embedding_result["embedding"]
        
        # (B) ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        retrieved_docs = retriever.run(query_embedding=[query_embedding])["documents"]
        
        if not retrieved_docs:
            emp = find_best_employee(question)

            if emp:
                dept = emp["department"]
                name = emp["name"]
                pos = emp["position"]
                phone = emp["phone"]

                return {
                    "response": (
                        f"í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ì •í™•í•œ ì•ˆë‚´ê°€ ì–´ë µìŠµë‹ˆë‹¤.\n"
                        f"ìì„¸í•œ ë‚´ìš©ì€ {dept} {name} {pos}ë‹˜({phone})ê»˜ ë¬¸ì˜ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
                    )
                }

            return {
                "response": (
                    "í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•´ ê´€ë ¨ ë¬¸ì„œì™€ ë‹´ë‹¹ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                    "ê²½ì˜ì§€ì›ë¶€ë¡œ ë¬¸ì˜ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
                )
            }

        
        prompt_docs = []
        for d in retrieved_docs:
            prompt_docs.append(
                Document(id=d.id, content=d.content, meta=d.meta)
    )

        prompt_result = prompt_builder.run(documents=prompt_docs, question=question)

        full_prompt = prompt_result["prompt"]
        
        # (D) Gemini APIë¡œ ë‹µë³€ ìƒì„±
        answer = create_gemini_response(full_prompt)
        print(f"[ë‹µë³€] ğŸ¤– (AI ìƒì„±): {answer}")
        return answer
        
    except Exception as e:
        error_msg = f"ì±—ë´‡ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        print(f"[ì˜¤ë¥˜] âŒ: {error_msg}")
        return error_msg


# if __name__ == "__main__":
#     # ì±—ë´‡ íŒŒì´í”„ë¼ì¸ 1íšŒ ì´ˆê¸°í™”
#     pipeline_components = initialize_chatbot()
    
#     if pipeline_components:
#         text_embedder, retriever, prompt_builder = pipeline_components
        
#         # (í…ŒìŠ¤íŠ¸)
        
#         # (1) FAQ ì§ˆë¬¸ (RAG ë¯¸ì‚¬ìš©)
#         ask_chatbot("ì—°ì°¨ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?", text_embedder, retriever, prompt_builder)
        
#         # (2) ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ (RAG ì‚¬ìš©)
#         ask_chatbot("ì •ë³´ê³µê°œë¥¼ ì²­êµ¬ë°›ì€ ë¶€ì„œëŠ” ë©°ì¹  ë‚´ì— ì²˜ë¦¬ í•´ì•¼í•´?", text_embedder, retriever, prompt_builder)

# ì±—ë´‡ ë¶€íŒ… ë¡œì§
@app.on_event("startup")
def startup_event():
    global text_embedder, retriever, prompt_builder
    pipeline_components = initialize_chatbot()
    if pipeline_components:
        text_embedder, retriever, prompt_builder = pipeline_components


@app.post("/api/chat")
async def chat(request: Request):
    global text_embedder, retriever, prompt_builder
    data = await request.json()
    question = data.get("message", "")
    print(f"ğŸ’¬ ì‚¬ìš©ì ì§ˆë¬¸: {question}")

    # 1ï¸âƒ£ ê·œì¹™ ê¸°ë°˜ FAQ ë¨¼ì € í™•ì¸
    for idx, keywords in enumerate(FAQ_KEYWORDS):
        for kw in keywords:
            if kw in question:
                return {"response": FIXED_FAQ_DATABASE[idx]}


    # 2ï¸âƒ£ RAG + Gemini í˜¸ì¶œ
    
    rep_keyword = find_representative_keyword(question)
    if rep_keyword:
        print(f"ğŸ” ë™ì˜ì–´ ë§¤í•‘: '{question}' â†’ '{rep_keyword}'")
        question = rep_keyword

    # 3ï¸âƒ£ ì§ˆë¬¸ ì„ë² ë”© ìƒì„± 
    query_emb = text_embedder.run(text=question)["embedding"]
    # 4ï¸âƒ£ DuckDB ê²€ìƒ‰
    docs = retriever.run(query_embedding=[query_emb])["documents"]
    print(f"DuckDB ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: {len(docs)}")

    if not docs:
        # ê´€ë ¨ ë¬¸ì„œ ì—†ìœ¼ë©´ ë‹´ë‹¹ì ì¶”ì²œ
        print("ğŸ” ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ â†’ ë‹´ë‹¹ì ì¶”ì²œ ë¡œì§ ì‹¤í–‰")
        emp = find_best_employee(question)

        if emp:
            dept = emp["department"]
            name = emp["name"]
            pos = emp["position"]
            phone = emp["phone"]

            return {
                "response": (
                    f"í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ì •í™•í•œ ì•ˆë‚´ê°€ ì–´ë µìŠµë‹ˆë‹¤.\n"
                    f"ìì„¸í•œ ë‚´ìš©ì€ {dept} {name} {pos}ë‹˜({phone})ê»˜ ë¬¸ì˜ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
                )
            }

        return {
            "response": (
                "í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•´ ê´€ë ¨ ë¬¸ì„œì™€ ë‹´ë‹¹ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
            )
        }

    # 6ï¸âƒ£ ë¬¸ì„œ ìˆìŒ â†’ RAG + Gemini
    prompt = prompt_builder.run(documents=docs, question=question)["prompt"]
    answer = create_gemini_response(prompt)
    # ì¶œì²˜ ì •ë³´ ì¶”ê°€ 
    # --- ğŸ”¥ ì¶œì²˜ í¬ë§·íŒ… ---
    try:
        raw_name = docs[0].meta.get("file_name", "ì¶œì²˜ ì •ë³´ ì—†ìŒ")
        # .txt ì œê±°
        if raw_name.lower().endswith(".txt"):
            clean_name = raw_name[:-4]
        else:
            clean_name = raw_name

        answer += f"\n\nğŸ“„ ì¶œì²˜: {clean_name}"

    except Exception:
        answer += "\n\nğŸ“„ ì¶œì²˜: ì•Œ ìˆ˜ ì—†ìŒ"
    return {"response": answer}
    
    # except Exception as e:
    #     return {"response": f"ì„œë²„ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}
    
@app.post("/api/faq")
async def faq(request: Request):
    data = await request.json()
    faq_number = data.get("faq_number")

    # ìˆ«ìê°€ ìœ íš¨í•œì§€ ê²€ì‚¬
    if faq_number is None or not isinstance(faq_number, int):
        return {"response": "FAQ ë²ˆí˜¸ê°€ ì˜ëª» ì „ë‹¬ë˜ì—ˆìŠµë‹ˆë‹¤."}

    # ë¦¬ìŠ¤íŠ¸ ë²”ìœ„ ê²€ì‚¬
    if faq_number < 0 or faq_number >= len(FIXED_FAQ_DATABASE):
        return {"response": "í•´ë‹¹ FAQ í•­ëª©ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}

    # í•´ë‹¹ FAQ ë‹µë³€ì„ ë°˜í™˜
    return {"response": FIXED_FAQ_DATABASE[faq_number]}
