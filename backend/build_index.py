# ìƒ‰ì¸ íŒŒì¼
import os
import argparse  # (1) ìˆ˜ë™ ì‹¤í–‰ ì˜µì…˜ì„ ë°›ê¸° ìœ„í•´ ì¶”ê°€
from haystack import Pipeline
# (2) DuckDBìš© ì»´í¬ë„ŒíŠ¸ë¡œ ë³€ê²½
from duckdb import DuckDBDocumentStore
from haystack.components.embedders import SentenceTransformersDocumentEmbedder
from haystack.components.preprocessors import DocumentSplitter
from haystack.components.converters import PyPDFToDocument

# --- 1. ê²½ë¡œ ë° ëª¨ë¸ ì„¤ì • ---

# (3) âœ¨ ì¤‘ìš”: í•œêµ­ì–´ ëª¨ë¸ë¡œ ë³€ê²½
# all-MiniLM-L6-v2 -> jhgan/ko-sbert-nli
EMBEDDING_MODEL = "jhgan/ko-sbert-nli" 
DB_PATH = "hibot_store.db" # (4) ì˜êµ¬ ì €ì¥ë  DB íŒŒì¼ ì´ë¦„
DATA_PATH = "/Users/jang-eunji/Desktop/hibot-chat/hibot-chat-docs-pdf"

def main(force_rebuild=False):
    print("ë¬¸ì„œ ìƒ‰ì¸ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # --- 2. ì˜êµ¬ ì €ì¥ì†Œ(DuckDB) ì´ˆê¸°í™” ---
    document_store = DuckDBDocumentStore(db_path=DB_PATH)
    
    if force_rebuild:
        print(f"--force ì˜µì…˜ ê°ì§€. '{DB_PATH}'ì˜ ëª¨ë“  ë¬¸ì„œë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.")
        document_store.delete_all_documents()

    # --- 3. ì¦ë¶„ ìƒ‰ì¸ (Incremental Indexing) ë¡œì§ ---
    
    # (A) DBì— ì´ë¯¸ ì €ì¥ëœ íŒŒì¼ ì´ë¦„ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    try:
        existing_docs = document_store.filter_documents()
        indexed_files = {doc.meta.get("file_name") for doc in existing_docs}
        print(f"í˜„ì¬ DBì— ìƒ‰ì¸ëœ íŒŒì¼ ìˆ˜: {len(indexed_files)}")
    except Exception as e:
        print(f"DB ì—°ê²° ì˜¤ë¥˜ (ì²˜ìŒ ì‹¤í–‰ ì‹œ ì •ìƒ): {e}")
        indexed_files = set()

    # (B) ì‹¤ì œ í´ë”ì— ìˆëŠ” PDF íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    current_pdf_files = {f for f in os.listdir(DATA_PATH) if f.endswith(".pdf")}
    
    # (C) ìƒˆë¡œ ì¶”ê°€ëœ íŒŒì¼ë§Œ í•„í„°ë§
    new_files_to_index = current_pdf_files - indexed_files
    
    if not new_files_to_index:
        print("âœ… ìƒˆë¡œ ì¶”ê°€ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒ‰ì¸ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    print(f"ğŸš¨ ì´ {len(new_files_to_index)}ê°œì˜ ìƒˆ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. ìƒ‰ì¸ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
    print(list(new_files_to_index))

    # --- 4. ìƒ‰ì¸ íŒŒì´í”„ë¼ì¸ ì»´í¬ë„ŒíŠ¸ ì¤€ë¹„ ---
    pdf_converter = PyPDFToDocument()
    splitter = DocumentSplitter(split_by="sentence", split_length=5)
    # (5) í•œêµ­ì–´ ëª¨ë¸ë¡œ ì„ë² ë” ì´ˆê¸°í™”
    document_embedder = SentenceTransformersDocumentEmbedder(model=EMBEDDING_MODEL)
    document_embedder.warm_up() # ëª¨ë¸ ë¡œë“œ

    # --- 5. ìƒˆ íŒŒì¼ë§Œ ìˆœíšŒí•˜ë©° ìƒ‰ì¸ ---
    try:
        for file_name in new_files_to_index:
            print(f"ì²˜ë¦¬ ì¤‘: {file_name}...")
            file_path = os.path.join(DATA_PATH, file_name)
            
            # 1. PDF ë³€í™˜
            docs = pdf_converter.run(sources=[file_path])["documents"]
            
            # 2. ë©”íƒ€ë°ì´í„°ì— 'file_name' ì¶”ê°€ (ì¶”ì ìš©)
            for doc in docs:
                doc.meta["file_name"] = file_name
            
            # 3. ë¬¸ì„œ ë¶„í•  (Chunking)
            split_docs = splitter.run(docs)["documents"]
            
            # 4. ì„ë² ë”© (ë¡œì»¬ ì‹¤í–‰)
            embedded_docs = document_embedder.run(split_docs)["documents"]
            
            # 5. DBì— ì €ì¥ (ì˜êµ¬)
            document_store.write_documents(embedded_docs)
            
        print(f"âœ… {len(new_files_to_index)}ê°œ íŒŒì¼ì˜ ìƒ‰ì¸ ë° ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ë¬¸ì„œ ìƒ‰ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# --- ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ---
if __name__ == "__main__":
    # (6) ìˆ˜ë™ìœ¼ë¡œ 'python build_index.py --force' ì‹¤í–‰ ì‹œ ì „ì²´ ì¬ìƒ‰ì¸
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--force",
        action="store_true",
        help="DBë¥¼ ê°•ì œë¡œ ë¹„ìš°ê³  ëª¨ë“  ë¬¸ì„œë¥¼ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ìƒ‰ì¸í•©ë‹ˆë‹¤."
    )
    args = parser.parse_args()
    
    main(force_rebuild=args.force)