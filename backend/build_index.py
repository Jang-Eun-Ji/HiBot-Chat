# ìƒ‰ì¸ íŒŒì¼
import os
import argparse  # (1) ìˆ˜ë™ ì‹¤í–‰ ì˜µì…˜ì„ ë°›ê¸° ìœ„í•´ ì¶”ê°€
import duckdb
import json
from haystack import Pipeline
from haystack.dataclasses import Document
from haystack.components.embedders import SentenceTransformersDocumentEmbedder
from haystack.components.preprocessors import DocumentSplitter
from haystack.components.converters import PyPDFToDocument

# --- 1. ê²½ë¡œ ë° ëª¨ë¸ ì„¤ì • ---

# (3) âœ¨ ì¤‘ìš”: ì•ˆì •ì ì¸ ëª¨ë¸ ì‚¬ìš© (SSL ë¬¸ì œ í•´ê²° í›„ í•œêµ­ì–´ ëª¨ë¸ë¡œ ë³€ê²½ ê°€ëŠ¥)
EMBEDDING_MODEL = "all-MiniLM-L6-v2"  # ì•ˆì •ì ì¸ ì˜ì–´ ëª¨ë¸
# EMBEDDING_MODEL = "jhgan/ko-sbert-nli"  # í•œêµ­ì–´ ëª¨ë¸ (SSL ë¬¸ì œ í•´ê²° í›„ ì‚¬ìš©)
DB_PATH = "hibot_store.db"  # (4) Pure DuckDB ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼
DATA_PATH = r"c:\Users\khis\Desktop\HiBot-Chat\hibot-chat-docs-pdf"  # Windows ê²½ë¡œ

class DuckDBDocumentStore:
    """Pure DuckDB document storage implementation"""
    def __init__(self, db_path):
        self.db_path = db_path
        self.conn = duckdb.connect(db_path)
        self._setup_tables()
    
    def _setup_tables(self):
        """Create necessary tables"""
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS documents (
                id TEXT PRIMARY KEY,
                content TEXT,
                meta TEXT,
                embedding DOUBLE[]
            )
        """)
        self.conn.commit()
    
    def write_documents(self, documents):
        """Write documents directly to DuckDB"""
        for doc in documents:
            meta_json = json.dumps(doc.meta) if doc.meta else "{}"
            embedding_list = doc.embedding.tolist() if doc.embedding is not None else None
            
            self.conn.execute("""
                INSERT OR REPLACE INTO documents (id, content, meta, embedding)
                VALUES (?, ?, ?, ?)
            """, (str(doc.id), doc.content, meta_json, embedding_list))
        self.conn.commit()
        print(f"âœ… {len(documents)}ê°œ ë¬¸ì„œë¥¼ DuckDBì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    
    def filter_documents(self, filters=None):
        """Get documents from DuckDB with optional filtering"""
        query = "SELECT id, content, meta, embedding FROM documents"
        
        # Add file_name filter if specified
        if filters and "meta" in filters:
            file_name = filters["meta"].get("file_name")
            if file_name:
                query += f" WHERE meta LIKE '%\"file_name\": \"{file_name}\"%'"
        
        result = self.conn.execute(query).fetchall()
        documents = []
        
        for row in result:
            doc_id, content, meta_str, embedding = row
            try:
                meta = json.loads(meta_str) if meta_str else {}
            except:
                meta = {}
                
            doc = Document(
                id=doc_id,
                content=content,
                meta=meta,
                embedding=embedding
            )
            documents.append(doc)
        
        return documents
    
    def count_documents(self):
        """Count documents in DuckDB"""
        result = self.conn.execute("SELECT COUNT(*) FROM documents").fetchone()
        return result[0] if result else 0
    
    def delete_all_documents(self):
        """Delete all documents from DuckDB"""
        self.conn.execute("DELETE FROM documents")
        self.conn.commit()
        print("ğŸ—‘ï¸ ëª¨ë“  ë¬¸ì„œê°€ DuckDBì—ì„œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")

def main(force_rebuild=False):
    print("ë¬¸ì„œ ìƒ‰ì¸ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # --- 2. ì˜êµ¬ ì €ì¥ì†Œ(DuckDB) ì´ˆê¸°í™” ---
    try:
        document_store = DuckDBDocumentStore(db_path=DB_PATH)
        print(f"âœ… DuckDB ì €ì¥ì†Œ '{DB_PATH}' ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ DuckDB ì €ì¥ì†Œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    if force_rebuild:
        print(f"--force ì˜µì…˜ ê°ì§€. '{DB_PATH}'ì˜ ëª¨ë“  ë¬¸ì„œë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.")
        document_store.delete_all_documents()

    # --- 3. ì¦ë¶„ ìƒ‰ì¸ (Incremental Indexing) ë¡œì§ ---
    
    # (A) DBì— ì´ë¯¸ ì €ì¥ëœ íŒŒì¼ ì´ë¦„ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    try:
        existing_docs = document_store.filter_documents({})
        indexed_files = {doc.meta.get("file_name") for doc in existing_docs if doc.meta.get("file_name")}
        print(f"í˜„ì¬ DBì— ìƒ‰ì¸ëœ íŒŒì¼ ìˆ˜: {len(indexed_files)}")
    except Exception as e:
        print(f"DB ì—°ê²° ì˜¤ë¥˜ (ì²˜ìŒ ì‹¤í–‰ ì‹œ ì •ìƒ): {e}")
        indexed_files = set()

    # (B) ì‹¤ì œ í´ë”ì— ìˆëŠ” PDF íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    if not os.path.exists(DATA_PATH):
        print(f"âŒ ë°ì´í„° í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DATA_PATH}")
        print("ğŸ“‹ í•´ê²°ë°©ë²•: ë‹¤ìŒ í´ë”ë¥¼ ìƒì„±í•˜ê³  PDF íŒŒì¼ì„ ì¶”ê°€í•˜ì„¸ìš”:")
        print(f"   mkdir \"{DATA_PATH}\"")
        return
    
    try:
        current_pdf_files = {f for f in os.listdir(DATA_PATH) if f.endswith(".pdf")}
    except Exception as e:
        print(f"âŒ í´ë” ì½ê¸° ì˜¤ë¥˜: {e}")
        return
    
    # (C) ìƒˆë¡œ ì¶”ê°€ëœ íŒŒì¼ë§Œ í•„í„°ë§
    new_files_to_index = current_pdf_files - indexed_files
    
    if not new_files_to_index:
        print("âœ… ìƒˆë¡œ ì¶”ê°€ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒ‰ì¸ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    print(f"ğŸš¨ ì´ {len(new_files_to_index)}ê°œì˜ ìƒˆ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. ìƒ‰ì¸ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
    print(list(new_files_to_index))

    # --- 4. ìƒ‰ì¸ íŒŒì´í”„ë¼ì¸ ì»´í¬ë„ŒíŠ¸ ì¤€ë¹„ ---
    pdf_converter = PyPDFToDocument()
    splitter = DocumentSplitter(split_by="sentence", split_length=5)
    
    # (5) ì„ë² ë” ì´ˆê¸°í™” (SSL ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨)
    try:
        document_embedder = SentenceTransformersDocumentEmbedder(model=EMBEDDING_MODEL)
        document_embedder.warm_up()  # ëª¨ë¸ ë¡œë“œ
        print(f"âœ… ì„ë² ë”© ëª¨ë¸ '{EMBEDDING_MODEL}' ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("ğŸ“‹ í•´ê²°ë°©ë²•:")
        print("   1. pip install --upgrade certifi")
        print("   2. ì¸í„°ë„· ì—°ê²° í™•ì¸")
        print("   3. ê¸°ì—… ë°©í™”ë²½ì¸ ê²½ìš° IT ë¶€ì„œ ë¬¸ì˜")
        return

    # --- 5. ìƒˆ íŒŒì¼ë§Œ ìˆœíšŒí•˜ë©° ìƒ‰ì¸ ---
    try:
        for file_name in new_files_to_index:
            print(f"ì²˜ë¦¬ ì¤‘: {file_name}...")
            file_path = os.path.join(DATA_PATH, file_name)
            
            # 1. PDF ë³€í™˜
            docs = pdf_converter.run(sources=[file_path])["documents"]
            
            # 2. ë©”íƒ€ë°ì´í„°ì— 'file_name' ì¶”ê°€ (ì¶”ì ìš©)
            for doc in docs:
                doc.meta["file_name"] = file_name
            
            # 3. ë¬¸ì„œ ë¶„í•  (Chunking)
            split_docs = splitter.run(docs)["documents"]
            
            # 4. ì„ë² ë”© (ë¡œì»¬ ì‹¤í–‰)
            embedded_docs = document_embedder.run(split_docs)["documents"]
            
            # 5. DBì— ì €ì¥ (ì˜êµ¬)
            document_store.write_documents(embedded_docs)
            
        print(f"âœ… {len(new_files_to_index)}ê°œ íŒŒì¼ì˜ ìƒ‰ì¸ ë° ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ğŸ“Š ì´ {document_store.count_documents()}ê°œì˜ ë¬¸ì„œê°€ DuckDBì— ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ë¬¸ì„œ ìƒ‰ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# --- ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ---
if __name__ == "__main__":
    # (6) ìˆ˜ë™ìœ¼ë¡œ 'python build_index.py --force' ì‹¤í–‰ ì‹œ ì „ì²´ ì¬ìƒ‰ì¸
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--force",
        action="store_true",
        help="DBë¥¼ ê°•ì œë¡œ ë¹„ìš°ê³  ëª¨ë“  ë¬¸ì„œë¥¼ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ìƒ‰ì¸í•©ë‹ˆë‹¤."
    )
    args = parser.parse_args()
    
    main(force_rebuild=args.force)